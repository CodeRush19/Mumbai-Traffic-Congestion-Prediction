{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eD8Fh41-Mb5",
        "outputId": "b04d55d2-de7d-40a0-cf8a-fe9d47774ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# File paths (Research_project folder ke andar)\n",
        "path_traffic_congestion = '/content/drive/MyDrive/Research_project/17 Gaële Lesteven - Traffic Congestion in Mumbai, Will Pu....pdf'\n",
        "path_IJIRT_paper = '/content/drive/MyDrive/Research_project/IJIRT176698_PAPER.pdf'\n",
        "path_mumbai_challans = '/content/drive/MyDrive/Research_project/mumbai-challans-2024.pdf'\n",
        "path_traffic_responses = '/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "path_research_paper = '/content/drive/MyDrive/Research_project/reserch paper.pdf'\n",
        "path_traffic_webinar = '/content/drive/MyDrive/Research_project/Taming-Traffic-Webinar-3-Congestion-Pricing-in-Mumbai.pdf'\n",
        "path_uwi_congestion = '/content/drive/MyDrive/Research_project/UWI-Congestion_Pricing_to_Decongest_Mumbai_c.pdf'\n",
        "\n",
        "# Example: Excel file load karna\n",
        "import pandas as pd\n",
        "df_responses = pd.read_excel(path_traffic_responses, sheet_name='Form Responses 1')\n",
        "\n",
        "# Agar PDFs ko read karna hai, toh PyPDF2 ya pdfplumber libraries install kar ke use kar sakte hain\n",
        "# Example install command (Colab notebook mein):\n",
        "# !pip install PyPDF2\n",
        "# or\n",
        "# !pip install pdfplumber\n"
      ],
      "metadata": {
        "id": "RFclzQr8_eoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "df = pd.read_excel(file_path, sheet_name='Form Responses 1')\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g15OmiOAKuc",
        "outputId": "901ea786-00dc-42aa-ed26-5489aaa9de03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                Timestamp                         Email              Name   \\\n",
            "0 2025-08-15 12:15:09.867    ashokkanojiya320@gmail.com    Ashok Kanojiya    \n",
            "1 2025-08-15 12:15:29.358      neetupandey582@gmail.com      Neetu pandey    \n",
            "2 2025-08-15 12:19:29.157       ankit233kumar@gmail.com       Ankit Kumar    \n",
            "3 2025-08-15 12:20:09.399     aditimahamulkar@gmail.com  Aditi Mahamulkar    \n",
            "4 2025-08-15 12:22:01.695  e1062240119@timscdrmumbai.in     Dhanush Dhotre   \n",
            "\n",
            "  What is Your age Group  Gender How often do you travel within Mumbai?    \\\n",
            "0            18–25 years    Male                                    Daily   \n",
            "1            18–25 years  Female                                    Daily   \n",
            "2            18–25 years    Male                         1–3 times a week   \n",
            "3            18–25 years  Female                                    Daily   \n",
            "4            18–25 years    Male                                    Daily   \n",
            "\n",
            "  On average, how much time do you spend in traffic daily?   \\\n",
            "0                                  Less than 30 mins          \n",
            "1                                  Less than 30 mins          \n",
            "2                                  Less than 30 mins          \n",
            "3                                  Less than 30 mins          \n",
            "4                                  Less than 30 mins          \n",
            "\n",
            "  Which mode of transportation do you use most frequently?   \\\n",
            "0                                              Metro          \n",
            "1                                        Local Train          \n",
            "2                                        Local Train          \n",
            "3                                        Local Train          \n",
            "4                         Private Vehicle (Car/Bike)          \n",
            "\n",
            "  How severe do you think traffic congestion is in Mumbai?    \\\n",
            "0                                           Moderate           \n",
            "1                                               High           \n",
            "2                                           Moderate           \n",
            "3                                               High           \n",
            "4                                               High           \n",
            "\n",
            "  What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)  \\\n",
            "0  Poor road infrastructure, Increasing number of...                                        \n",
            "1  Increasing number of private vehicles, Ineffic...                                        \n",
            "2  Increasing number of private vehicles, Road co...                                        \n",
            "3  Increasing number of private vehicles, Road co...                                        \n",
            "4  Poor road infrastructure, Increasing number of...                                        \n",
            "\n",
            "  How does traffic congestion affect your daily life?    \\\n",
            "0                    Missed appointments/work delays      \n",
            "1                             Stress and frustration      \n",
            "2                              No significant effect      \n",
            "3                            Higher fuel consumption      \n",
            "4                             Stress and frustration      \n",
            "\n",
            "  Are you aware that Artificial Intelligence can be used to predict traffic congestion?    \\\n",
            "0                                                Yes                                        \n",
            "1                                                Yes                                        \n",
            "2                                           Not Sure                                        \n",
            "3                                                Yes                                        \n",
            "4                                                 No                                        \n",
            "\n",
            "  If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?    \\\n",
            "0                                             Likely                                                               \n",
            "1                                             Likely                                                               \n",
            "2                                        Very likely                                                               \n",
            "3                                             Likely                                                               \n",
            "4                                      Very unlikely                                                               \n",
            "\n",
            "  Which features would you like most in an AI-based traffic prediction app?    \\\n",
            "0  Real-time traffic updates, Alternative route s...                            \n",
            "1               Public transport timings integration                            \n",
            "2  Real-time traffic updates, Alternative route s...                            \n",
            "3                          Real-time traffic updates                            \n",
            "4                          Real-time traffic updates                            \n",
            "\n",
            "  In your opinion, can AI help reduce traffic congestion in Mumbai?    \\\n",
            "0                                Yes, to some extent                    \n",
            "1                                 Yes, significantly                    \n",
            "2                                           Not sure                    \n",
            "3                                 Yes, significantly                    \n",
            "4                     No, it won’t make a difference                    \n",
            "\n",
            "  What suggestions would you give to improve traffic congestion in Mumbai?    \n",
            "0  Promote more use of public transport like buse...                          \n",
            "1  \\nIncrease public transport frequency and prom...                          \n",
            "2  Underground roads , high frequency of buses an...                          \n",
            "3                                                NaN                          \n",
            "4  Use public vehicle as much as you can & road s...                          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Upload file manually in Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Step 2: Load the uploaded Excel file (adjust filename as per upload)\n",
        "file_name = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(file_name, sheet_name='Form Responses 1')\n",
        "\n",
        "# Step 3: Strip any whitespace from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Step 4: Display initial data info and sample\n",
        "print(\"Initial Data Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nSample Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 5: Drop columns not useful for modeling\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "df_clean = df.drop(columns=drop_cols)\n",
        "\n",
        "# Step 6: Drop rows with missing values\n",
        "df_clean = df_clean.dropna()\n",
        "\n",
        "# Step 7: Convert categorical columns to numerical codes\n",
        "categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    df_clean[col] = df_clean[col].astype('category').cat.codes\n",
        "\n",
        "# Step 8: Show cleaned data info and sample\n",
        "print(\"\\nCleaned Data Info:\")\n",
        "print(df_clean.info())\n",
        "print(\"\\nCleaned Data Sample:\")\n",
        "print(df_clean.head())\n",
        "\n",
        "# Step 9: Save cleaned data for future model training\n",
        "df_clean.to_csv('cleaned_traffic_data.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "90iO-XMNM48n",
        "outputId": "d0f9022c-bdd4-46d7-8e60-a6d48bd68c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9c36561d-1126-4f4d-be75-47224aae750f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9c36561d-1126-4f4d-be75-47224aae750f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx to Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx\n",
            "Initial Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 57 entries, 0 to 56\n",
            "Data columns (total 16 columns):\n",
            " #   Column                                                                                                        Non-Null Count  Dtype         \n",
            "---  ------                                                                                                        --------------  -----         \n",
            " 0   Timestamp                                                                                                     57 non-null     datetime64[ns]\n",
            " 1   Email                                                                                                         57 non-null     object        \n",
            " 2   Name                                                                                                          57 non-null     object        \n",
            " 3   What is Your age Group                                                                                        57 non-null     object        \n",
            " 4   Gender                                                                                                        57 non-null     object        \n",
            " 5   How often do you travel within Mumbai?                                                                        57 non-null     object        \n",
            " 6   On average, how much time do you spend in traffic daily?                                                      57 non-null     object        \n",
            " 7   Which mode of transportation do you use most frequently?                                                      57 non-null     object        \n",
            " 8   How severe do you think traffic congestion is in Mumbai?                                                      57 non-null     object        \n",
            " 9   What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)                       57 non-null     object        \n",
            " 10  How does traffic congestion affect your daily life?                                                           57 non-null     object        \n",
            " 11  Are you aware that Artificial Intelligence can be used to predict traffic congestion?                         57 non-null     object        \n",
            " 12  If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  57 non-null     object        \n",
            " 13  Which features would you like most in an AI-based traffic prediction app?                                     57 non-null     object        \n",
            " 14  In your opinion, can AI help reduce traffic congestion in Mumbai?                                             57 non-null     object        \n",
            " 15  What suggestions would you give to improve traffic congestion in Mumbai?                                      23 non-null     object        \n",
            "dtypes: datetime64[ns](1), object(15)\n",
            "memory usage: 7.3+ KB\n",
            "None\n",
            "\n",
            "Sample Data:\n",
            "                Timestamp                         Email               Name  \\\n",
            "0 2025-08-15 12:15:09.867    ashokkanojiya320@gmail.com    Ashok Kanojiya    \n",
            "1 2025-08-15 12:15:29.358      neetupandey582@gmail.com      Neetu pandey    \n",
            "2 2025-08-15 12:19:29.157       ankit233kumar@gmail.com       Ankit Kumar    \n",
            "3 2025-08-15 12:20:09.399     aditimahamulkar@gmail.com  Aditi Mahamulkar    \n",
            "4 2025-08-15 12:22:01.695  e1062240119@timscdrmumbai.in     Dhanush Dhotre   \n",
            "\n",
            "  What is Your age Group  Gender How often do you travel within Mumbai?  \\\n",
            "0            18–25 years    Male                                  Daily   \n",
            "1            18–25 years  Female                                  Daily   \n",
            "2            18–25 years    Male                       1–3 times a week   \n",
            "3            18–25 years  Female                                  Daily   \n",
            "4            18–25 years    Male                                  Daily   \n",
            "\n",
            "  On average, how much time do you spend in traffic daily?  \\\n",
            "0                                  Less than 30 mins         \n",
            "1                                  Less than 30 mins         \n",
            "2                                  Less than 30 mins         \n",
            "3                                  Less than 30 mins         \n",
            "4                                  Less than 30 mins         \n",
            "\n",
            "  Which mode of transportation do you use most frequently?  \\\n",
            "0                                              Metro         \n",
            "1                                        Local Train         \n",
            "2                                        Local Train         \n",
            "3                                        Local Train         \n",
            "4                         Private Vehicle (Car/Bike)         \n",
            "\n",
            "  How severe do you think traffic congestion is in Mumbai?  \\\n",
            "0                                           Moderate         \n",
            "1                                               High         \n",
            "2                                           Moderate         \n",
            "3                                               High         \n",
            "4                                               High         \n",
            "\n",
            "  What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)  \\\n",
            "0  Poor road infrastructure, Increasing number of...                                        \n",
            "1  Increasing number of private vehicles, Ineffic...                                        \n",
            "2  Increasing number of private vehicles, Road co...                                        \n",
            "3  Increasing number of private vehicles, Road co...                                        \n",
            "4  Poor road infrastructure, Increasing number of...                                        \n",
            "\n",
            "  How does traffic congestion affect your daily life?  \\\n",
            "0                    Missed appointments/work delays    \n",
            "1                             Stress and frustration    \n",
            "2                              No significant effect    \n",
            "3                            Higher fuel consumption    \n",
            "4                             Stress and frustration    \n",
            "\n",
            "  Are you aware that Artificial Intelligence can be used to predict traffic congestion?  \\\n",
            "0                                                Yes                                      \n",
            "1                                                Yes                                      \n",
            "2                                           Not Sure                                      \n",
            "3                                                Yes                                      \n",
            "4                                                 No                                      \n",
            "\n",
            "  If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  \\\n",
            "0                                             Likely                                                             \n",
            "1                                             Likely                                                             \n",
            "2                                        Very likely                                                             \n",
            "3                                             Likely                                                             \n",
            "4                                      Very unlikely                                                             \n",
            "\n",
            "  Which features would you like most in an AI-based traffic prediction app?  \\\n",
            "0  Real-time traffic updates, Alternative route s...                          \n",
            "1               Public transport timings integration                          \n",
            "2  Real-time traffic updates, Alternative route s...                          \n",
            "3                          Real-time traffic updates                          \n",
            "4                          Real-time traffic updates                          \n",
            "\n",
            "  In your opinion, can AI help reduce traffic congestion in Mumbai?  \\\n",
            "0                                Yes, to some extent                  \n",
            "1                                 Yes, significantly                  \n",
            "2                                           Not sure                  \n",
            "3                                 Yes, significantly                  \n",
            "4                     No, it won’t make a difference                  \n",
            "\n",
            "  What suggestions would you give to improve traffic congestion in Mumbai?  \n",
            "0  Promote more use of public transport like buse...                        \n",
            "1  \\nIncrease public transport frequency and prom...                        \n",
            "2  Underground roads , high frequency of buses an...                        \n",
            "3                                                NaN                        \n",
            "4  Use public vehicle as much as you can & road s...                        \n",
            "\n",
            "Cleaned Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 57 entries, 0 to 56\n",
            "Data columns (total 12 columns):\n",
            " #   Column                                                                                                        Non-Null Count  Dtype\n",
            "---  ------                                                                                                        --------------  -----\n",
            " 0   What is Your age Group                                                                                        57 non-null     int8 \n",
            " 1   Gender                                                                                                        57 non-null     int8 \n",
            " 2   How often do you travel within Mumbai?                                                                        57 non-null     int8 \n",
            " 3   On average, how much time do you spend in traffic daily?                                                      57 non-null     int8 \n",
            " 4   Which mode of transportation do you use most frequently?                                                      57 non-null     int8 \n",
            " 5   How severe do you think traffic congestion is in Mumbai?                                                      57 non-null     int8 \n",
            " 6   What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)                       57 non-null     int8 \n",
            " 7   How does traffic congestion affect your daily life?                                                           57 non-null     int8 \n",
            " 8   Are you aware that Artificial Intelligence can be used to predict traffic congestion?                         57 non-null     int8 \n",
            " 9   If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  57 non-null     int8 \n",
            " 10  Which features would you like most in an AI-based traffic prediction app?                                     57 non-null     int8 \n",
            " 11  In your opinion, can AI help reduce traffic congestion in Mumbai?                                             57 non-null     int8 \n",
            "dtypes: int8(12)\n",
            "memory usage: 816.0 bytes\n",
            "None\n",
            "\n",
            "Cleaned Data Sample:\n",
            "   What is Your age Group  Gender  How often do you travel within Mumbai?  \\\n",
            "0                       0       1                                       2   \n",
            "1                       0       0                                       2   \n",
            "2                       0       1                                       0   \n",
            "3                       0       0                                       2   \n",
            "4                       0       1                                       2   \n",
            "\n",
            "   On average, how much time do you spend in traffic daily?  \\\n",
            "0                                                  2          \n",
            "1                                                  2          \n",
            "2                                                  2          \n",
            "3                                                  2          \n",
            "4                                                  2          \n",
            "\n",
            "   Which mode of transportation do you use most frequently?  \\\n",
            "0                                                  2          \n",
            "1                                                  1          \n",
            "2                                                  1          \n",
            "3                                                  1          \n",
            "4                                                  3          \n",
            "\n",
            "   How severe do you think traffic congestion is in Mumbai?  \\\n",
            "0                                                  2          \n",
            "1                                                  0          \n",
            "2                                                  2          \n",
            "3                                                  0          \n",
            "4                                                  0          \n",
            "\n",
            "   What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)  \\\n",
            "0                                                 11                                         \n",
            "1                                                  3                                         \n",
            "2                                                  4                                         \n",
            "3                                                  4                                         \n",
            "4                                                 13                                         \n",
            "\n",
            "   How does traffic congestion affect your daily life?  \\\n",
            "0                                                  2     \n",
            "1                                                  4     \n",
            "2                                                  3     \n",
            "3                                                  0     \n",
            "4                                                  4     \n",
            "\n",
            "   Are you aware that Artificial Intelligence can be used to predict traffic congestion?  \\\n",
            "0                                                  2                                       \n",
            "1                                                  2                                       \n",
            "2                                                  1                                       \n",
            "3                                                  2                                       \n",
            "4                                                  0                                       \n",
            "\n",
            "   If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  \\\n",
            "0                                                  0                                                              \n",
            "1                                                  0                                                              \n",
            "2                                                  3                                                              \n",
            "3                                                  0                                                              \n",
            "4                                                  4                                                              \n",
            "\n",
            "   Which features would you like most in an AI-based traffic prediction app?  \\\n",
            "0                                                 14                           \n",
            "1                                                  5                           \n",
            "2                                                 11                           \n",
            "3                                                  6                           \n",
            "4                                                  6                           \n",
            "\n",
            "   In your opinion, can AI help reduce traffic congestion in Mumbai?  \n",
            "0                                                  3                  \n",
            "1                                                  2                  \n",
            "2                                                  1                  \n",
            "3                                                  2                  \n",
            "4                                                  0                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Step 1: Upload and load cleaned dataset if you saved it before, or load original and clean here\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_name = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(file_name, sheet_name='Form Responses 1')\n",
        "\n",
        "# Step 2: Clean the data\n",
        "df.columns = df.columns.str.strip()\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "df_clean = df.drop(columns=drop_cols)\n",
        "df_clean = df_clean.dropna()\n",
        "\n",
        "# Step 3: Encode categorical columns numerically\n",
        "categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    df_clean[col] = df_clean[col].astype('category').cat.codes\n",
        "\n",
        "# Step 4: Define features and target\n",
        "X = df_clean.drop(columns=['How severe do you think traffic congestion is in Mumbai?'])\n",
        "y = df_clean['How severe do you think traffic congestion is in Mumbai?']\n",
        "\n",
        "# Step 5: Split data into training and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 6: Train Random Forest classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 7: Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "wHvc3oM8NfUb",
        "outputId": "9307b87b-cc03-483b-9a03-f582664d0d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cf8517b1-9cc6-44b6-b897-2fdb00faf1eb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cf8517b1-9cc6-44b6-b897-2fdb00faf1eb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx to Predicting Traffic Congestion in Mumbai Using AI (Responses) (1).xlsx\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.86      0.71         7\n",
            "           2       0.50      0.25      0.33         4\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.58        12\n",
            "   macro avg       0.37      0.37      0.35        12\n",
            "weighted avg       0.52      0.58      0.52        12\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save model to file\n",
        "joblib.dump(model, 'traffic_congestion_model.joblib')\n",
        "\n",
        "# Later you can load it as:\n",
        "# model = joblib.load('traffic_congestion_model.joblib')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeYpf4scNwqw",
        "outputId": "b1dbfc76-fd78-43da-da22-483596d1a47b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['traffic_congestion_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "# Example function to check if alert needed based on current time and predicted congestion\n",
        "def check_traffic_alert(user_route, journey_start_time, model, feature_data):\n",
        "    \"\"\"\n",
        "    user_route: str, user's regular travel route\n",
        "    journey_start_time: datetime object, user planned start time\n",
        "    model: trained ML model for prediction\n",
        "    feature_data: dict or DataFrame of features for prediction for the route and time\n",
        "\n",
        "    Returns: alert message or None\n",
        "    \"\"\"\n",
        "    # Calculate alert time (30 mins before journey)\n",
        "    alert_time = journey_start_time - datetime.timedelta(minutes=30)\n",
        "\n",
        "    # Get current time\n",
        "    current_time = datetime.datetime.now()\n",
        "\n",
        "    if current_time >= alert_time:\n",
        "        # Prepare features for prediction from feature_data\n",
        "        # For example, encode user_route and other relevant features\n",
        "        # Replace with actual feature extraction and preprocessing\n",
        "        X = feature_data\n",
        "\n",
        "        # Predict congestion probability/class\n",
        "        prediction = model.predict(X)\n",
        "\n",
        "        if prediction == 1:  # assuming 1 = congestion predicted\n",
        "            return f\"Alert: Traffic congestion expected on your route {user_route} at {journey_start_time}.\"\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Usage example (fill with actual inputs)\n",
        "# alert = check_traffic_alert('Western Express Highway', datetime.datetime(2025, 9, 18, 8, 0), model, some_feature_data)\n",
        "# if alert:\n",
        "#     print(alert)\n"
      ],
      "metadata": {
        "id": "LKQ1RLKDOsu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e675q7IePVjY",
        "outputId": "37c19a4f-bb42-4469-ccfb-00572100ffe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# List uploaded files\n",
        "for filename in uploaded.keys():\n",
        "    print(f'Uploaded file: {filename}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "UbC6zHQCPiBZ",
        "outputId": "d7293b43-bd25-46cd-da37-c02ca5fd4ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-61a3d491-b2e6-453f-8f1d-5dd164f76e45\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-61a3d491-b2e6-453f-8f1d-5dd164f76e45\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 17 Gaële Lesteven - Traffic Congestion in Mumbai, Will Public Authorities take the Opportunity to Leapfrog.pdf to 17 Gaële Lesteven - Traffic Congestion in Mumbai, Will Public Authorities take the Opportunity to Leapfrog.pdf\n",
            "Saving IJIRT176698_PAPER.pdf to IJIRT176698_PAPER.pdf\n",
            "Saving mumbai-challans-2024.pdf to mumbai-challans-2024.pdf\n",
            "Saving reserch paper.pdf to reserch paper.pdf\n",
            "Saving Taming-Traffic-Webinar-3-Congestion-Pricing-in-Mumbai_8.11.21.pptx.pdf to Taming-Traffic-Webinar-3-Congestion-Pricing-in-Mumbai_8.11.21.pptx.pdf\n",
            "Saving UWI-Congestion_Pricing_to_Decongest_Mumbai_c.pdf to UWI-Congestion_Pricing_to_Decongest_Mumbai_c.pdf\n",
            "Uploaded file: 17 Gaële Lesteven - Traffic Congestion in Mumbai, Will Public Authorities take the Opportunity to Leapfrog.pdf\n",
            "Uploaded file: IJIRT176698_PAPER.pdf\n",
            "Uploaded file: mumbai-challans-2024.pdf\n",
            "Uploaded file: reserch paper.pdf\n",
            "Uploaded file: Taming-Traffic-Webinar-3-Congestion-Pricing-in-Mumbai_8.11.21.pptx.pdf\n",
            "Uploaded file: UWI-Congestion_Pricing_to_Decongest_Mumbai_c.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "pdf_files = [\n",
        "    '17 Gaële Lesteven - Traffic Congestion in Mumbai, Will Public Authorities take the Opportunity to Leapfrog.pdf',\n",
        "    'IJIRT176698_PAPER.pdf',\n",
        "    'mumbai-challans-2024.pdf',\n",
        "    'reserch paper.pdf',\n",
        "    'Taming-Traffic-Webinar-3-Congestion-Pricing-in-Mumbai_8.11.21.pptx.pdf',\n",
        "    'UWI-Congestion_Pricing_to_Decongest_Mumbai_c.pdf'\n",
        "]\n",
        "\n",
        "def extract_text(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    full_text = \"\"\n",
        "    for page in doc:\n",
        "        full_text += page.get_text()\n",
        "    return full_text\n",
        "\n",
        "def extract_mentions(text, keywords):\n",
        "    pattern = re.compile('|'.join(keywords), re.IGNORECASE)\n",
        "    matches = pattern.findall(text)\n",
        "    return len(matches)\n",
        "\n",
        "extracted_data = []\n",
        "\n",
        "for pdf_file in pdf_files:\n",
        "    text = extract_text(pdf_file)\n",
        "    accident_count = extract_mentions(text, ['accident', 'crash', 'collision', 'fatality', 'injury'])\n",
        "    congestion_count = extract_mentions(text, ['congestion', 'traffic jam', 'gridlock'])\n",
        "\n",
        "    extracted_data.append({\n",
        "        'pdf_file': pdf_file,\n",
        "        'accident_mentions': accident_count,\n",
        "        'congestion_mentions': congestion_count\n",
        "    })\n",
        "\n",
        "df_secondary = pd.DataFrame(extracted_data)\n",
        "df_secondary.to_csv('secondary_traffic_data.csv', index=False)\n",
        "print(df_secondary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slK2baPVP_4r",
        "outputId": "fb88ecdd-836f-4076-c417-1dbad0dfc243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            pdf_file  accident_mentions  \\\n",
            "0  17 Gaële Lesteven - Traffic Congestion in Mumb...                  0   \n",
            "1                              IJIRT176698_PAPER.pdf                  1   \n",
            "2                           mumbai-challans-2024.pdf                  0   \n",
            "3                                  reserch paper.pdf                  1   \n",
            "4  Taming-Traffic-Webinar-3-Congestion-Pricing-in...                  0   \n",
            "5   UWI-Congestion_Pricing_to_Decongest_Mumbai_c.pdf                  1   \n",
            "\n",
            "   congestion_mentions  \n",
            "0                   23  \n",
            "1                   18  \n",
            "2                    0  \n",
            "3                   81  \n",
            "4                   34  \n",
            "5                  613  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load primary cleaned survey data CSV (assumes already cleaned and saved)\n",
        "primary_df = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Load secondary data CSV you just created\n",
        "secondary_df = pd.read_csv('secondary_traffic_data.csv')\n",
        "\n",
        "# For demo, we will merge datasets based on no common key, just add secondary features to every row\n",
        "# You might want to join on common keys like dates, routes if you extract such info\n",
        "\n",
        "for col in ['accident_mentions', 'congestion_mentions']:\n",
        "    primary_df[col] = secondary_df[col].mean()  # Example: assign mean mentions as global features\n",
        "\n",
        "print(primary_df.head())\n",
        "\n",
        "# Now you can proceed to retrain your model with the enriched dataset (with secondary features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7ZuGSZqQSWz",
        "outputId": "c52f45f9-5041-4371-cc30-930bc6133f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   What is Your age Group  Gender  How often do you travel within Mumbai?  \\\n",
            "0                       0       1                                       2   \n",
            "1                       0       0                                       2   \n",
            "2                       0       1                                       0   \n",
            "3                       0       0                                       2   \n",
            "4                       0       1                                       2   \n",
            "\n",
            "   On average, how much time do you spend in traffic daily?  \\\n",
            "0                                                  2          \n",
            "1                                                  2          \n",
            "2                                                  2          \n",
            "3                                                  2          \n",
            "4                                                  2          \n",
            "\n",
            "   Which mode of transportation do you use most frequently?  \\\n",
            "0                                                  2          \n",
            "1                                                  1          \n",
            "2                                                  1          \n",
            "3                                                  1          \n",
            "4                                                  3          \n",
            "\n",
            "   How severe do you think traffic congestion is in Mumbai?  \\\n",
            "0                                                  2          \n",
            "1                                                  0          \n",
            "2                                                  2          \n",
            "3                                                  0          \n",
            "4                                                  0          \n",
            "\n",
            "   What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)  \\\n",
            "0                                                 11                                         \n",
            "1                                                  3                                         \n",
            "2                                                  4                                         \n",
            "3                                                  4                                         \n",
            "4                                                 13                                         \n",
            "\n",
            "   How does traffic congestion affect your daily life?  \\\n",
            "0                                                  2     \n",
            "1                                                  4     \n",
            "2                                                  3     \n",
            "3                                                  0     \n",
            "4                                                  4     \n",
            "\n",
            "   Are you aware that Artificial Intelligence can be used to predict traffic congestion?  \\\n",
            "0                                                  2                                       \n",
            "1                                                  2                                       \n",
            "2                                                  1                                       \n",
            "3                                                  2                                       \n",
            "4                                                  0                                       \n",
            "\n",
            "   If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  \\\n",
            "0                                                  0                                                              \n",
            "1                                                  0                                                              \n",
            "2                                                  3                                                              \n",
            "3                                                  0                                                              \n",
            "4                                                  4                                                              \n",
            "\n",
            "   Which features would you like most in an AI-based traffic prediction app?  \\\n",
            "0                                                 14                           \n",
            "1                                                  5                           \n",
            "2                                                 11                           \n",
            "3                                                  6                           \n",
            "4                                                  6                           \n",
            "\n",
            "   In your opinion, can AI help reduce traffic congestion in Mumbai?  \\\n",
            "0                                                  3                   \n",
            "1                                                  2                   \n",
            "2                                                  1                   \n",
            "3                                                  2                   \n",
            "4                                                  0                   \n",
            "\n",
            "   accident_mentions  congestion_mentions  \n",
            "0                0.5           128.166667  \n",
            "1                0.5           128.166667  \n",
            "2                0.5           128.166667  \n",
            "3                0.5           128.166667  \n",
            "4                0.5           128.166667  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the enriched dataset after combining\n",
        "df = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Assuming you already merged secondary features into this CSV\n",
        "\n",
        "# Define target and features again\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'  # adjust if needed\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR5A77ZbQbr0",
        "outputId": "eba8c439-3af9-4801-aa05-2dd50df74e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.86      0.71         7\n",
            "           2       0.50      0.25      0.33         4\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.58        12\n",
            "   macro avg       0.37      0.37      0.35        12\n",
            "weighted avg       0.52      0.58      0.52        12\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load combined dataset\n",
        "df = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Define target and features\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train RandomForest with class_weight balanced\n",
        "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOH5OW5lQzay",
        "outputId": "9ec41ad1-a089-4295-991c-57c43b07f920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.86      0.71         7\n",
            "           2       0.00      0.00      0.00         4\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50        12\n",
            "   macro avg       0.20      0.29      0.24        12\n",
            "weighted avg       0.35      0.50      0.41        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load combined dataset\n",
        "df = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Define target and features\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Remove rare class 1 from training\n",
        "mask = y_train != 1\n",
        "X_train_mod = X_train[mask]\n",
        "y_train_mod = y_train[mask]\n",
        "\n",
        "# Apply SMOTE to training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train_mod, y_train_mod)\n",
        "\n",
        "# Train classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "id": "wgxaT-fXRPQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e647919-9f28-4ff9-f5ee-77aa428dc592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.43      0.55         7\n",
            "           2       0.67      0.50      0.57         4\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.42        12\n",
            "   macro avg       0.47      0.31      0.37        12\n",
            "weighted avg       0.66      0.42      0.51        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Binary target: congested (labels 2, 3) vs not congested (0, 1)\n",
        "df['binary_congestion'] = df['How severe do you think traffic congestion is in Mumbai?'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
        "\n",
        "X = df.drop(columns=['How severe do you think traffic congestion is in Mumbai?', 'binary_congestion'])\n",
        "y = df['binary_congestion']\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle class imbalance with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFH_GwLloqrx",
        "outputId": "bfcf9764-b8b8-44d6-e5a5-b9c988421821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.57      0.57         7\n",
            "           1       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.50        12\n",
            "   macro avg       0.49      0.49      0.49        12\n",
            "weighted avg       0.50      0.50      0.50        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Prepare binary target as before\n",
        "df['binary_congestion'] = df['How severe do you think traffic congestion is in Mumbai?'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
        "\n",
        "X = df.drop(columns=['How severe do you think traffic congestion is in Mumbai?', 'binary_congestion'])\n",
        "y = df['binary_congestion']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model and parameter grid\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='f1')\n",
        "\n",
        "# Fit on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predict and evaluate on test data with best estimator\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSfiPvjtpE5k",
        "outputId": "8eff1ad0-8ccc-444b-9116-610abe463af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.71      0.67         7\n",
            "           1       0.50      0.40      0.44         5\n",
            "\n",
            "    accuracy                           0.58        12\n",
            "   macro avg       0.56      0.56      0.56        12\n",
            "weighted avg       0.57      0.58      0.57        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Drop or encode necessary columns\n",
        "categorical_cols = ['What is Your age Group', 'Gender', 'How often do you travel within Mumbai?',\n",
        "                    'On average, how much time do you spend in traffic daily?',\n",
        "                    'Which mode of transportation do you use most frequently?',\n",
        "                    'Are you aware that Artificial Intelligence can be used to predict traffic congestion?',\n",
        "                    'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?',\n",
        "                    'Which features would you like most in an AI-based traffic prediction app?',\n",
        "                    'In your opinion, can AI help reduce traffic congestion in Mumbai?']\n",
        "\n",
        "df = pd.get_dummies(df, columns=categorical_cols)\n",
        "\n",
        "# Continue with binary target and model training steps as before\n"
      ],
      "metadata": {
        "id": "V6NchTcopurA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define model and parameter grid as before\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best params:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnVz_rV6pxG-",
        "outputId": "cec196d3-5969-41d7-9b59-025b19eb1818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'class_weight': 'balanced', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train_res, y_train_res)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QXDfR-Op0nM",
        "outputId": "77360fee-8e39-45e2-b803-70d88f3f43f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:48:37] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.57      0.57         7\n",
            "           1       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.50        12\n",
            "   macro avg       0.49      0.49      0.49        12\n",
            "weighted avg       0.50      0.50      0.50        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Binary target: congested (2, 3) -> 1 else 0\n",
        "df['binary_congestion'] = df['How severe do you think traffic congestion is in Mumbai?'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
        "\n",
        "# Select categorical columns to encode\n",
        "categorical_cols = ['What is Your age Group', 'Gender', 'How often do you travel within Mumbai?',\n",
        "                    'On average, how much time do you spend in traffic daily?',\n",
        "                    'Which mode of transportation do you use most frequently?',\n",
        "                    'Are you aware that Artificial Intelligence can be used to predict traffic congestion?',\n",
        "                    'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?',\n",
        "                    'Which features would you like most in an AI-based traffic prediction app?',\n",
        "                    'In your opinion, can AI help reduce traffic congestion in Mumbai?']\n",
        "\n",
        "# One-hot encode categorical features\n",
        "df = pd.get_dummies(df, columns=categorical_cols)\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=['How severe do you think traffic congestion is in Mumbai?', 'binary_congestion'])\n",
        "y = df['binary_congestion']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle class imbalance with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Define Random Forest and parameter grid for tuning\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "# GridSearch with 3-fold CV (reduce folds for speed if needed)\n",
        "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate best model on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRadEKPkqeyn",
        "outputId": "c20c667a-dd0e-4f3c-b9c5-6bdf7e85aebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'class_weight': None, 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.57      0.62         7\n",
            "           1       0.50      0.60      0.55         5\n",
            "\n",
            "    accuracy                           0.58        12\n",
            "   macro avg       0.58      0.59      0.58        12\n",
            "weighted avg       0.60      0.58      0.59        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the cleaned survey dataset CSV\n",
        "df = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Convert target to binary classes: congested (2,3) = 1, not congested (0,1) = 0\n",
        "df['binary_congestion'] = df['How severe do you think traffic congestion is in Mumbai?'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
        "\n",
        "# Columns to one-hot encode (categorical features)\n",
        "categorical_cols = [\n",
        "    'What is Your age Group',\n",
        "    'Gender',\n",
        "    'How often do you travel within Mumbai?',\n",
        "    'On average, how much time do you spend in traffic daily?',\n",
        "    'Which mode of transportation do you use most frequently?',\n",
        "    'Are you aware that Artificial Intelligence can be used to predict traffic congestion?',\n",
        "    'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?',\n",
        "    'Which features would you like most in an AI-based traffic prediction app?',\n",
        "    'In your opinion, can AI help reduce traffic congestion in Mumbai?'\n",
        "]\n",
        "\n",
        "# One-hot encode these categorical features\n",
        "df = pd.get_dummies(df, columns=categorical_cols)\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=['How severe do you think traffic congestion is in Mumbai?', 'binary_congestion'])\n",
        "y = df['binary_congestion']\n",
        "\n",
        "# Split data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle class imbalance with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Define the model and hyperparameters for tuning\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "# Grid Search with cross-validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Show best hyperparameters\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsq3-Jt5rLzz",
        "outputId": "2f5d2a84-d7fa-43d8-e919-05eda5eed108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'class_weight': None, 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.57      0.62         7\n",
            "           1       0.50      0.60      0.55         5\n",
            "\n",
            "    accuracy                           0.58        12\n",
            "   macro avg       0.58      0.59      0.58        12\n",
            "weighted avg       0.60      0.58      0.59        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example: synthetic external numeric data based on your PDFs\n",
        "external_data = {\n",
        "    'common_key': ['Mumbai'],  # Adjust to proper route/date keys if available\n",
        "    'accident_mentions': [0.5],   # Mean or sample values from PDFs\n",
        "    'congestion_mentions': [128.17]\n",
        "}\n",
        "\n",
        "df_external = pd.DataFrame(external_data)\n",
        "\n",
        "# Load your main dataset\n",
        "df_main = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Add the external data columns to main dataset by assigning mean/global values\n",
        "for col in ['accident_mentions', 'congestion_mentions']:\n",
        "    df_main[col] = df_external[col].mean()\n",
        "\n",
        "# Now df_main has new numeric features you can use for training...\n",
        "\n",
        "# Continue with one-hot encoding, target preparation, train/test split, etc.\n"
      ],
      "metadata": {
        "id": "YNbsqJA7rlsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load main survey dataset\n",
        "df_main = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Synthetic external numeric features (means derived from PDFs or placeholder)\n",
        "accident_mean = 0.5\n",
        "congestion_mean = 128.17\n",
        "\n",
        "# Add synthetic external features as columns\n",
        "df_main['accident_mentions'] = accident_mean\n",
        "df_main['congestion_mentions'] = congestion_mean\n",
        "\n",
        "# Convert target to binary\n",
        "df_main['binary_congestion'] = df_main['How severe do you think traffic congestion is in Mumbai?'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
        "\n",
        "# One-hot encode categorical features\n",
        "categorical_cols = [\n",
        "    'What is Your age Group',\n",
        "    'Gender',\n",
        "    'How often do you travel within Mumbai?',\n",
        "    'On average, how much time do you spend in traffic daily?',\n",
        "    'Which mode of transportation do you use most frequently?',\n",
        "    'Are you aware that Artificial Intelligence can be used to predict traffic congestion?',\n",
        "    'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?',\n",
        "    'Which features would you like most in an AI-based traffic prediction app?',\n",
        "    'In your opinion, can AI help reduce traffic congestion in Mumbai?'\n",
        "]\n",
        "df_main = pd.get_dummies(df_main, columns=categorical_cols)\n",
        "\n",
        "# Define features and target\n",
        "X = df_main.drop(columns=['How severe do you think traffic congestion is in Mumbai?', 'binary_congestion'])\n",
        "y = df_main['binary_congestion']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to address class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Hyperparameter grid for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "# GridSearch with 3-fold CV\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYWEo1rGsFju",
        "outputId": "4984ef10-d72e-44f2-86d7-45c62c953952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'class_weight': None, 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.57      0.62         7\n",
            "           1       0.50      0.60      0.55         5\n",
            "\n",
            "    accuracy                           0.58        12\n",
            "   macro avg       0.58      0.59      0.58        12\n",
            "weighted avg       0.60      0.58      0.59        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X, y prepared as before\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=None, min_samples_split=2, class_weight=None)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(rf, X, y, cv=cv, scoring='f1')\n",
        "\n",
        "print(\"Cross-validation F1 scores:\", scores)\n",
        "print(\"Mean F1 score:\", np.mean(scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAIFAeUwsc4p",
        "outputId": "bdadf5b0-5e2e-4915-9dd3-281ca6fef029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation F1 scores: [0.44444444 0.66666667 0.66666667 0.28571429 0.33333333]\n",
            "Mean F1 score: 0.4793650793650793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load primary survey data\n",
        "df_main = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Assume secondary data extracted from PDFs summarised as:\n",
        "secondary_features = {\n",
        "    'accident_mentions': 0.5,      # Mean accident mentions from reports\n",
        "    'congestion_mentions': 128.17  # Mean congestion mentions\n",
        "}\n",
        "\n",
        "# Add these secondary features as new columns repeated for all rows\n",
        "df_main['accident_mentions'] = secondary_features['accident_mentions']\n",
        "df_main['congestion_mentions'] = secondary_features['congestion_mentions']\n",
        "\n",
        "# Binary target (congested vs not)\n",
        "df_main['binary_congestion'] = df_main['How severe do you think traffic congestion is in Mumbai?']\\\n",
        "                                .apply(lambda x: 1 if x in [2, 3] else 0)\n",
        "\n",
        "# One-hot encode categorical features\n",
        "categorical_cols = [\n",
        "    'What is Your age Group', 'Gender', 'How often do you travel within Mumbai?',\n",
        "    'On average, how much time do you spend in traffic daily?', 'Which mode of transportation do you use most frequently?',\n",
        "    'Are you aware that Artificial Intelligence can be used to predict traffic congestion?',\n",
        "    'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?',\n",
        "    'Which features would you like most in an AI-based traffic prediction app?',\n",
        "    'In your opinion, can AI help reduce traffic congestion in Mumbai?'\n",
        "]\n",
        "df_main = pd.get_dummies(df_main, columns=categorical_cols)\n",
        "\n",
        "X = df_main.drop(columns=['How severe do you think traffic congestion is in Mumbai?', 'binary_congestion'])\n",
        "y = df_main['binary_congestion']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Define models for ensemble\n",
        "rf = RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced')\n",
        "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "ensemble = VotingClassifier(estimators=[('rf', rf), ('xgb', xgb)], voting='soft')\n",
        "\n",
        "# Cross-validation evaluation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(ensemble, X_train_res, y_train_res, cv=cv, scoring='f1')\n",
        "print(f\"CV F1 scores: {cv_scores}\")\n",
        "print(f\"Average CV F1 score: {cv_scores.mean()}\")\n",
        "\n",
        "# Train on full training data\n",
        "ensemble.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Predictions and evaluation on test data\n",
        "y_pred = ensemble.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkf1PcX3tp6a",
        "outputId": "09e9ca1b-d9ba-4c31-e4c7-20c88a9f2bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:49:09] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:49:09] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:49:09] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:49:10] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:49:10] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV F1 scores: [0.8        0.76923077 0.4        0.72727273 0.5       ]\n",
            "Average CV F1 score: 0.6393006993006993\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.57      0.57         7\n",
            "           1       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.50        12\n",
            "   macro avg       0.49      0.49      0.49        12\n",
            "weighted avg       0.50      0.50      0.50        12\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:49:10] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load your existing cleaned and preprocessed dataset (after encoding etc.)\n",
        "df = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Convert target to binary as before\n",
        "df['binary_congestion'] = df['How severe do you think traffic congestion is in Mumbai?'].apply(lambda x: 1 if x in [2,3] else 0)\n",
        "\n",
        "# Prepare feature set and target\n",
        "X = df.drop(columns=['How severe do you think traffic congestion is in Mumbai?', 'binary_congestion'])\n",
        "y = df['binary_congestion']\n",
        "\n",
        "# Initialize SMOTE for total size 500 samples\n",
        "smote = SMOTE(sampling_strategy={0: 250, 1: 250}, random_state=42)  # Balanced oversampling equal samples\n",
        "\n",
        "# Generate synthetic data\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "\n",
        "print(\"Original dataset size:\", len(X))\n",
        "print(\"New dataset size after SMOTE:\", len(X_res))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kudwLZeluAfZ",
        "outputId": "86aa0b3d-adc3-4db3-9941-a948ea71d960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 57\n",
            "New dataset size after SMOTE: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Split synthetic dataset into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
        "\n",
        "# Setup Random Forest with param grid\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate on test data\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngx0yEBYuH9d",
        "outputId": "748f90fd-d6d7-4f62-b0ba-7f85af6ebb4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'class_weight': None, 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96        42\n",
            "           1       0.98      0.97      0.97        58\n",
            "\n",
            "    accuracy                           0.97       100\n",
            "   macro avg       0.97      0.97      0.97       100\n",
            "weighted avg       0.97      0.97      0.97       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming you have a hold-out test set X_test, y_test\n",
        "\n",
        "# Predict on unseen test data\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Test set performance:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1V9Hf8EufUv",
        "outputId": "67d4ed07-2149-4519-d5c3-533506faf872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96        42\n",
            "           1       0.98      0.97      0.97        58\n",
            "\n",
            "    accuracy                           0.97       100\n",
            "   macro avg       0.97      0.97      0.97       100\n",
            "weighted avg       0.97      0.97      0.97       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(X_train, y_train, X_test, y_test):\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "wdLMxL9Lug8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create synthetic weather data for 30 days\n",
        "dates = pd.date_range(start='2025-08-01', periods=30, freq='D')\n",
        "\n",
        "weather_data = {\n",
        "    'date': dates,\n",
        "    'temperature_C': np.random.normal(loc=30, scale=5, size=30),  # Average 30C with some variance\n",
        "    'rainfall_mm': np.random.choice([0, 0, 0, 5, 10, 15], size=30),  # Most days no rain, some rain days\n",
        "    'humidity_percent': np.random.uniform(50, 90, size=30),  # Humidity from 50% to 90%\n",
        "    'wind_speed_kmph': np.random.uniform(5, 20, size=30),  # Wind speed between 5 and 20 kmph\n",
        "}\n",
        "\n",
        "df_weather = pd.DataFrame(weather_data)\n",
        "\n",
        "# Save to CSV\n",
        "df_weather.to_csv('weather.csv', index=False)\n",
        "\n",
        "print(df_weather.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMsPfwbluj4n",
        "outputId": "a113e93b-0e11-400b-937e-43c686bf8f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        date  temperature_C  rainfall_mm  humidity_percent  wind_speed_kmph\n",
            "0 2025-08-01      35.890921           15         77.898876         9.681843\n",
            "1 2025-08-02      32.979038            0         82.915099         7.456040\n",
            "2 2025-08-03      34.507099            0         66.829951        18.704770\n",
            "3 2025-08-04      23.821383            5         60.640582        18.366889\n",
            "4 2025-08-05      38.116309            0         80.254881        16.111512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_main.head()\n",
        "df_main.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQVOrS8HvY5L",
        "outputId": "1e3ecf2a-e72f-4ec3-f8cb-8c668c4df9b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['How severe do you think traffic congestion is in Mumbai?',\n",
              "       'What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)',\n",
              "       'How does traffic congestion affect your daily life?',\n",
              "       'accident_mentions', 'congestion_mentions', 'binary_congestion',\n",
              "       'What is Your age Group_0', 'What is Your age Group_1',\n",
              "       'What is Your age Group_2', 'What is Your age Group_3', 'Gender_0',\n",
              "       'Gender_1', 'How often do you travel within Mumbai?_0',\n",
              "       'How often do you travel within Mumbai?_1',\n",
              "       'How often do you travel within Mumbai?_2',\n",
              "       'How often do you travel within Mumbai?_3',\n",
              "       'On average, how much time do you spend in traffic daily?_0',\n",
              "       'On average, how much time do you spend in traffic daily?_1',\n",
              "       'On average, how much time do you spend in traffic daily?_2',\n",
              "       'On average, how much time do you spend in traffic daily?_3',\n",
              "       'Which mode of transportation do you use most frequently?_0',\n",
              "       'Which mode of transportation do you use most frequently?_1',\n",
              "       'Which mode of transportation do you use most frequently?_2',\n",
              "       'Which mode of transportation do you use most frequently?_3',\n",
              "       'Which mode of transportation do you use most frequently?_4',\n",
              "       'Are you aware that Artificial Intelligence can be used to predict traffic congestion?_0',\n",
              "       'Are you aware that Artificial Intelligence can be used to predict traffic congestion?_1',\n",
              "       'Are you aware that Artificial Intelligence can be used to predict traffic congestion?_2',\n",
              "       'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?_0',\n",
              "       'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?_1',\n",
              "       'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?_2',\n",
              "       'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?_3',\n",
              "       'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?_4',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_0',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_1',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_2',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_3',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_4',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_5',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_6',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_7',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_8',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_9',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_10',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_11',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_12',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_13',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_14',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_15',\n",
              "       'Which features would you like most in an AI-based traffic prediction app?_16',\n",
              "       'In your opinion, can AI help reduce traffic congestion in Mumbai?_0',\n",
              "       'In your opinion, can AI help reduce traffic congestion in Mumbai?_1',\n",
              "       'In your opinion, can AI help reduce traffic congestion in Mumbai?_2',\n",
              "       'In your opinion, can AI help reduce traffic congestion in Mumbai?_3'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_main['date'] = pd.date_range(start='2025-08-01', periods=len(df_main), freq='D')\n"
      ],
      "metadata": {
        "id": "08Gh82O1vg89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_main['avg_temperature'] = 30  # Example mean temperature\n",
        "df_main['avg_rainfall'] = 5      # Example rainfall\n"
      ],
      "metadata": {
        "id": "-PH1UQmpvjag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_main = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Add synthetic date starting from '2025-08-01'\n",
        "df_main['date'] = pd.date_range(start='2025-08-01', periods=len(df_main), freq='D')\n",
        "\n",
        "print(df_main[['date']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCZNfm6iv5h2",
        "outputId": "2b4a9e75-522c-44ad-da16-e7019637b1e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        date\n",
            "0 2025-08-01\n",
            "1 2025-08-02\n",
            "2 2025-08-03\n",
            "3 2025-08-04\n",
            "4 2025-08-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with column mean for numeric columns\n",
        "X_train = X_train.fillna(X_train.mean())\n",
        "\n",
        "# For categorical columns (one-hot), fill NaN with 0 or mode if needed\n",
        "X_train = X_train.fillna(0)\n",
        "\n",
        "# Then apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "D1dQ-Ho4wiP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load main dataset\n",
        "df_main = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Add synthetic 'date' column\n",
        "df_main['date'] = pd.date_range(start='2025-08-01', periods=len(df_main), freq='D')\n",
        "\n",
        "# Load synthetic weather data\n",
        "df_weather = pd.read_csv('weather.csv')\n",
        "df_weather['date'] = pd.to_datetime(df_weather['date'])\n",
        "\n",
        "# Merge on 'date'\n",
        "df_merged = pd.merge(df_main, df_weather, on='date', how='left')\n",
        "\n",
        "# Create binary target\n",
        "df_merged['binary_congestion'] = df_merged['How severe do you think traffic congestion is in Mumbai?'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
        "\n",
        "# List original categorical columns (already one-hot encoded in df_merged, so drop them)\n",
        "categorical_original_names = [\n",
        "    'What is Your age Group', 'Gender',\n",
        "    'How often do you travel within Mumbai?', 'On average, how much time do you spend in traffic daily?',\n",
        "    'Which mode of transportation do you use most frequently?',\n",
        "    'Are you aware that Artificial Intelligence can be used to predict traffic congestion?',\n",
        "    'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?',\n",
        "    'Which features would you like most in an AI-based traffic prediction app?',\n",
        "    'In your opinion, can AI help reduce traffic congestion in Mumbai?'\n",
        "]\n",
        "\n",
        "# Prepare features and target\n",
        "X = df_merged.drop(columns=['How severe do you think traffic congestion is in Mumbai?', 'binary_congestion', 'date'] + categorical_original_names)\n",
        "y = df_merged['binary_congestion']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "# Apply SMOTE for class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train_imputed, y_train)\n",
        "\n",
        "# Train Random Forest model\n",
        "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_imputed)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6G3sOFVvnMo",
        "outputId": "d6d7b6b2-d16d-4725-9168-a3777ee5f2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.43      0.46         7\n",
            "           1       0.33      0.40      0.36         5\n",
            "\n",
            "    accuracy                           0.42        12\n",
            "   macro avg       0.42      0.41      0.41        12\n",
            "weighted avg       0.43      0.42      0.42        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load base survey dataset\n",
        "df_main = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Create or load your secondary data sources - here synthetic example features\n",
        "np.random.seed(42)\n",
        "num_samples = len(df_main)\n",
        "\n",
        "secondary_features = pd.DataFrame({\n",
        "    'accident_count': np.random.poisson(2, num_samples),  # Example accident counts\n",
        "    'festival_flag': np.random.choice([0, 1], num_samples, p=[0.9, 0.1]),  # Festivals affect traffic\n",
        "    'holiday_flag': np.random.choice([0, 1], num_samples, p=[0.85, 0.15])\n",
        "})\n",
        "\n",
        "# Add into main dataset\n",
        "df_main = pd.concat([df_main, secondary_features], axis=1)\n",
        "\n",
        "# Add synthetic date column if not exists\n",
        "if 'date' not in df_main.columns:\n",
        "    df_main['date'] = pd.date_range(start='2025-08-01', periods=num_samples, freq='D')\n",
        "\n",
        "# Also merge with weather data if available\n",
        "# df_weather = pd.read_csv('weather.csv')\n",
        "# df_main = df_main.merge(df_weather, on='date', how='left')\n"
      ],
      "metadata": {
        "id": "zu9KZAyLyLum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load main dataset\n",
        "df_main = pd.read_csv('cleaned_traffic_data.csv')\n",
        "\n",
        "# Add synthetic 'date' column for merging\n",
        "df_main['date'] = pd.date_range(start='2025-08-01', periods=len(df_main), freq='D')\n",
        "\n",
        "# Load synthetic weather data\n",
        "df_weather = pd.read_csv('weather.csv')\n",
        "df_weather['date'] = pd.to_datetime(df_weather['date'])\n",
        "\n",
        "# Merge datasets on 'date'\n",
        "df_merged = pd.merge(df_main, df_weather, on='date', how='left')\n",
        "\n",
        "# Target creation\n",
        "df_merged['binary_congestion'] = df_merged['How severe do you think traffic congestion is in Mumbai?'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
        "\n",
        "# List original categorical column names matching your dataset (adjust as per your exact columns)\n",
        "categorical_columns = [\n",
        "    'What is Your age Group', 'Gender', 'How often do you travel within Mumbai?',\n",
        "    'On average, how much time do you spend in traffic daily?', 'Which mode of transportation do you use most frequently?',\n",
        "    'Are you aware that Artificial Intelligence can be used to predict traffic congestion?',\n",
        "    'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?',\n",
        "    'Which features would you like most in an AI-based traffic prediction app?',\n",
        "    'In your opinion, can AI help reduce traffic congestion in Mumbai?'\n",
        "]\n",
        "\n",
        "# One-hot encode categoricals\n",
        "df_encoded = pd.get_dummies(df_merged, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Prepare features and target\n",
        "X = df_encoded.drop(columns=['How severe do you think traffic congestion is in Mumbai?', 'binary_congestion', 'date'])\n",
        "y = df_encoded['binary_congestion']\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Impute missing numeric data\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "# Balance with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train_imputed, y_train)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_imputed)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlR7hfI-yNej",
        "outputId": "b98d1559-f40e-49de-87b6-7fb7b8dd045b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.71      0.67         7\n",
            "           1       0.50      0.40      0.44         5\n",
            "\n",
            "    accuracy                           0.58        12\n",
            "   macro avg       0.56      0.56      0.56        12\n",
            "weighted avg       0.57      0.58      0.57        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uyHBmxiz8k5",
        "outputId": "a3bee4d9-0e4b-4bc1-ca97-24ecf7d514b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'reserch paper.pdf', 'mumbai-challans-2024.pdf', 'weather.csv', 'Taming-Traffic-Webinar-3-Congestion-Pricing-in-Mumbai_8.11.21.pptx.pdf', 'Predicting Traffic Congestion in Mumbai Using AI (Responses) (1).xlsx', '17 Gaële Lesteven - Traffic Congestion in Mumbai, Will Public Authorities take the Opportunity to Leapfrog.pdf', 'secondary_traffic_data.csv', 'Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx', 'UWI-Congestion_Pricing_to_Decongest_Mumbai_c.pdf', 'cleaned_traffic_data.csv', 'IJIRT176698_PAPER.pdf', 'traffic_congestion_model.joblib', 'drive', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_main = pd.read_excel('Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx')\n",
        "\n",
        "print(df_main.head())  # Verify loading\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n7vbRDJzmSh",
        "outputId": "733a3c65-e3ca-4ab4-f4c2-51330f0e8814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Timestamp                         Email              Name   \\\n",
            "0 2025-08-15 12:15:09.867    ashokkanojiya320@gmail.com    Ashok Kanojiya    \n",
            "1 2025-08-15 12:15:29.358      neetupandey582@gmail.com      Neetu pandey    \n",
            "2 2025-08-15 12:19:29.157       ankit233kumar@gmail.com       Ankit Kumar    \n",
            "3 2025-08-15 12:20:09.399     aditimahamulkar@gmail.com  Aditi Mahamulkar    \n",
            "4 2025-08-15 12:22:01.695  e1062240119@timscdrmumbai.in     Dhanush Dhotre   \n",
            "\n",
            "  What is Your age Group  Gender How often do you travel within Mumbai?    \\\n",
            "0            18–25 years    Male                                    Daily   \n",
            "1            18–25 years  Female                                    Daily   \n",
            "2            18–25 years    Male                         1–3 times a week   \n",
            "3            18–25 years  Female                                    Daily   \n",
            "4            18–25 years    Male                                    Daily   \n",
            "\n",
            "  On average, how much time do you spend in traffic daily?   \\\n",
            "0                                  Less than 30 mins          \n",
            "1                                  Less than 30 mins          \n",
            "2                                  Less than 30 mins          \n",
            "3                                  Less than 30 mins          \n",
            "4                                  Less than 30 mins          \n",
            "\n",
            "  Which mode of transportation do you use most frequently?   \\\n",
            "0                                              Metro          \n",
            "1                                        Local Train          \n",
            "2                                        Local Train          \n",
            "3                                        Local Train          \n",
            "4                         Private Vehicle (Car/Bike)          \n",
            "\n",
            "  How severe do you think traffic congestion is in Mumbai?    \\\n",
            "0                                           Moderate           \n",
            "1                                               High           \n",
            "2                                           Moderate           \n",
            "3                                               High           \n",
            "4                                               High           \n",
            "\n",
            "  What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)  \\\n",
            "0  Poor road infrastructure, Increasing number of...                                        \n",
            "1  Increasing number of private vehicles, Ineffic...                                        \n",
            "2  Increasing number of private vehicles, Road co...                                        \n",
            "3  Increasing number of private vehicles, Road co...                                        \n",
            "4  Poor road infrastructure, Increasing number of...                                        \n",
            "\n",
            "  How does traffic congestion affect your daily life?    \\\n",
            "0                    Missed appointments/work delays      \n",
            "1                             Stress and frustration      \n",
            "2                              No significant effect      \n",
            "3                            Higher fuel consumption      \n",
            "4                             Stress and frustration      \n",
            "\n",
            "  Are you aware that Artificial Intelligence can be used to predict traffic congestion?    \\\n",
            "0                                                Yes                                        \n",
            "1                                                Yes                                        \n",
            "2                                           Not Sure                                        \n",
            "3                                                Yes                                        \n",
            "4                                                 No                                        \n",
            "\n",
            "  If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?    \\\n",
            "0                                             Likely                                                               \n",
            "1                                             Likely                                                               \n",
            "2                                        Very likely                                                               \n",
            "3                                             Likely                                                               \n",
            "4                                      Very unlikely                                                               \n",
            "\n",
            "  Which features would you like most in an AI-based traffic prediction app?    \\\n",
            "0  Real-time traffic updates, Alternative route s...                            \n",
            "1               Public transport timings integration                            \n",
            "2  Real-time traffic updates, Alternative route s...                            \n",
            "3                          Real-time traffic updates                            \n",
            "4                          Real-time traffic updates                            \n",
            "\n",
            "  In your opinion, can AI help reduce traffic congestion in Mumbai?    \\\n",
            "0                                Yes, to some extent                    \n",
            "1                                 Yes, significantly                    \n",
            "2                                           Not sure                    \n",
            "3                                 Yes, significantly                    \n",
            "4                     No, it won’t make a difference                    \n",
            "\n",
            "  What suggestions would you give to improve traffic congestion in Mumbai?    \n",
            "0  Promote more use of public transport like buse...                          \n",
            "1  \\nIncrease public transport frequency and prom...                          \n",
            "2  Underground roads , high frequency of buses an...                          \n",
            "3                                                NaN                          \n",
            "4  Use public vehicle as much as you can & road s...                          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_main.columns.tolist())\n",
        "print('binary_congestion' in df_main.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqfV8ORI25IR",
        "outputId": "cb90c458-a382-4df6-816d-ce997b3bd509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Timestamp', 'Email', 'Name ', 'What is Your age Group', 'Gender', 'How often do you travel within Mumbai?  ', 'On average, how much time do you spend in traffic daily? ', 'Which mode of transportation do you use most frequently? ', 'How severe do you think traffic congestion is in Mumbai?  ', 'What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)', 'How does traffic congestion affect your daily life?  ', 'Are you aware that Artificial Intelligence can be used to predict traffic congestion?  ', 'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  ', 'Which features would you like most in an AI-based traffic prediction app?  ', 'In your opinion, can AI help reduce traffic congestion in Mumbai?  ', 'What suggestions would you give to improve traffic congestion in Mumbai?  ']\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_main = pd.read_excel('Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx')\n",
        "df_main.columns = df_main.columns.str.strip()\n",
        "print(df_main.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rxcg_6n3BGF",
        "outputId": "72a63668-85b4-42e6-9c9d-1f44bda1cd68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Timestamp', 'Email', 'Name', 'What is Your age Group', 'Gender', 'How often do you travel within Mumbai?', 'On average, how much time do you spend in traffic daily?', 'Which mode of transportation do you use most frequently?', 'How severe do you think traffic congestion is in Mumbai?', 'What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)', 'How does traffic congestion affect your daily life?', 'Are you aware that Artificial Intelligence can be used to predict traffic congestion?', 'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?', 'Which features would you like most in an AI-based traffic prediction app?', 'In your opinion, can AI help reduce traffic congestion in Mumbai?', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_main.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-bWiFHq0nCr",
        "outputId": "5fe3a2b5-659a-4571-9433-9a368f7118b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Timestamp', 'Email', 'Name', 'What is Your age Group', 'Gender', 'How often do you travel within Mumbai?', 'On average, how much time do you spend in traffic daily?', 'Which mode of transportation do you use most frequently?', 'How severe do you think traffic congestion is in Mumbai?', 'What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)', 'How does traffic congestion affect your daily life?', 'Are you aware that Artificial Intelligence can be used to predict traffic congestion?', 'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?', 'Which features would you like most in an AI-based traffic prediction app?', 'In your opinion, can AI help reduce traffic congestion in Mumbai?', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load data\n",
        "file_path = '/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "df = pd.read_excel(file_path, sheet_name='Form Responses 1')\n",
        "\n",
        "# Remove trailing spaces from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "print(\"Columns in dataset:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Define columns to drop if they exist\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "existing_drop_cols = [col for col in drop_cols if col in df.columns]\n",
        "\n",
        "df_clean = df.drop(columns=existing_drop_cols)\n",
        "df_clean.dropna(inplace=True)\n",
        "\n",
        "# Encode categorical columns\n",
        "for col in df_clean.select_dtypes(include=['object']).columns:\n",
        "    df_clean[col] = df_clean[col].astype('category').cat.codes\n",
        "\n",
        "# Define target column properly (after strip)\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "\n",
        "# Create binary congestion label\n",
        "df_clean['binary_congestion'] = df[target_col].apply(lambda x: 1 if x in [2,3] else 0)\n",
        "\n",
        "# Synthetic augmentation function\n",
        "def augment_data(df, sample_size):\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    synthetic_data = []\n",
        "    for _ in range(sample_size):\n",
        "        sample = df.sample(1).copy()\n",
        "        for col in numeric_cols:\n",
        "            noise = np.random.normal(0, 0.1 * abs(sample[col].values[0]))\n",
        "            sample[col] += noise\n",
        "        synthetic_data.append(sample)\n",
        "    df_synthetic = pd.concat(synthetic_data, ignore_index=True)\n",
        "    return pd.concat([df, df_synthetic], ignore_index=True)\n",
        "\n",
        "augmented_df = augment_data(df_clean, 1000)\n",
        "\n",
        "X = augmented_df.drop(columns=['binary_congestion'])\n",
        "y = augmented_df['binary_congestion']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Final dataset shape:\", augmented_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzezm7mREN75",
        "outputId": "620defb3-dba0-4e94-c984-568854783ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Columns in dataset:\n",
            "Index(['Timestamp', 'Email', 'Name', 'What is Your age Group', 'Gender',\n",
            "       'How often do you travel within Mumbai?',\n",
            "       'On average, how much time do you spend in traffic daily?',\n",
            "       'Which mode of transportation do you use most frequently?',\n",
            "       'How severe do you think traffic congestion is in Mumbai?',\n",
            "       'What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)',\n",
            "       'How does traffic congestion affect your daily life?',\n",
            "       'Are you aware that Artificial Intelligence can be used to predict traffic congestion?',\n",
            "       'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?',\n",
            "       'Which features would you like most in an AI-based traffic prediction app?',\n",
            "       'In your opinion, can AI help reduce traffic congestion in Mumbai?',\n",
            "       'What suggestions would you give to improve traffic congestion in Mumbai?'],\n",
            "      dtype='object')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       212\n",
            "\n",
            "    accuracy                           1.00       212\n",
            "   macro avg       1.00      1.00      1.00       212\n",
            "weighted avg       1.00      1.00      1.00       212\n",
            "\n",
            "Final dataset shape: (1057, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Data Load & Clean\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "file_path = '/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "df = pd.read_excel(file_path, sheet_name='Form Responses 1')\n",
        "df.columns = df.columns.str.strip()\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "df_clean = df.drop(columns=[c for c in drop_cols if c in df.columns]).dropna()\n",
        "for col in df_clean.select_dtypes(include=['object']).columns:\n",
        "    df_clean[col] = df_clean[col].astype('category').cat.codes\n",
        "df_clean['binary_congestion'] = df['How severe do you think traffic congestion is in Mumbai?'].apply(lambda x: 1 if x in [2, 3] else 0)\n",
        "\n",
        "# 3. Synthetic augmentation\n",
        "def augment(df, count):\n",
        "    num_cols = df.select_dtypes(np.number).columns\n",
        "    synthetic = []\n",
        "    for _ in range(count):\n",
        "        sample = df.sample(1).copy()\n",
        "        for c in num_cols:\n",
        "            sample[c] += np.random.normal(0, 0.1 * abs(sample[c].values[0]))\n",
        "        synthetic.append(sample)\n",
        "    return pd.concat([df]+synthetic, ignore_index=True)\n",
        "aug_df = augment(df_clean, 1000)\n",
        "\n",
        "# 4. Train/Test split & model training\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "X = aug_df.drop(columns=['binary_congestion'])\n",
        "y = aug_df['binary_congestion']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Data shape after augmentation:\", aug_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpOZUviXF0vD",
        "outputId": "080c187d-a6b5-4b3b-d9b2-459839dd8f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       212\n",
            "\n",
            "    accuracy                           1.00       212\n",
            "   macro avg       1.00      1.00      1.00       212\n",
            "weighted avg       1.00      1.00      1.00       212\n",
            "\n",
            "Data shape after augmentation: (1057, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Random Forest base model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Parameter grid define karo\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200, 500],\n",
        "    'max_depth': [None, 10, 20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Randomized Search setup\n",
        "random_search = RandomizedSearchCV(\n",
        "    rf, param_distributions=param_dist,\n",
        "    n_iter=20, cv=5, verbose=2,\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train on training data (X_train, y_train)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n",
        "# Best model se predict karo test data pe\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluation report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULy6yP0pGt7I",
        "outputId": "060d98d6-d97f-41b1-81ea-76cdbad38cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best parameters: {'n_estimators': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 10, 'bootstrap': False}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       212\n",
            "\n",
            "    accuracy                           1.00       212\n",
            "   macro avg       1.00      1.00      1.00       212\n",
            "weighted avg       1.00      1.00      1.00       212\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Paths\n",
        "primary_path = '/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "secondary_path = '/content/drive/MyDrive/Research_project/secondary_traffic_data.csv'\n",
        "\n",
        "df_primary = pd.read_excel(primary_path, sheet_name='Form Responses 1')\n",
        "df_secondary = pd.read_csv(secondary_path)\n",
        "\n",
        "df_primary.columns = df_primary.columns.str.strip()\n",
        "df_secondary.columns = df_secondary.columns.str.strip()\n",
        "\n",
        "# Merging logic (date column se merge karo agar dono me ho)\n",
        "merge_key = 'date'\n",
        "if merge_key in df_primary.columns and merge_key in df_secondary.columns:\n",
        "    df_primary[merge_key] = pd.to_datetime(df_primary[merge_key], errors='coerce')\n",
        "    df_secondary[merge_key] = pd.to_datetime(df_secondary[merge_key], errors='coerce')\n",
        "    df_merged = pd.merge(df_primary, df_secondary, on=merge_key, how='inner')\n",
        "else:\n",
        "    # Agar merge key nahi, simple concat (axis=1 se rows combine hongi)\n",
        "    df_merged = pd.concat([df_primary, df_secondary], axis=1)\n",
        "\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "df_merged.drop(columns=[c for c in drop_cols if c in df_merged.columns], inplace=True, errors='ignore')\n",
        "\n",
        "df_merged.dropna(inplace=True)\n",
        "\n",
        "for col in df_merged.select_dtypes(include=['object']).columns:\n",
        "    df_merged[col] = df_merged[col].astype('category').cat.codes\n",
        "\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "df_merged['binary_congestion'] = df_merged[target_col].apply(lambda x: 1 if x in [2,3] else 0)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X = df_merged.drop(columns=[target_col, 'binary_congestion'], errors='ignore')\n",
        "y = df_merged['binary_congestion']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Final merged dataset shape:', df_merged.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Am-_4zhKPvY",
        "outputId": "2cc5e553-1381-4ef0-cec4-39e1794da6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "Final merged dataset shape: (6, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_primary.shape)\n",
        "print(df_secondary.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6MoV9POKjpE",
        "outputId": "782be4a6-12a0-43dc-8127-808e267b7351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57, 16)\n",
            "(6, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(df, n_samples):\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    augmented_samples = []\n",
        "    for _ in range(n_samples):\n",
        "        sample = df.sample(1).copy()\n",
        "        for col in numeric_cols:\n",
        "            noise = np.random.normal(0, 0.1 * abs(sample[col].values[0]))\n",
        "            sample[col] += noise\n",
        "        augmented_samples.append(sample)\n",
        "    df_augmented = pd.concat(augmented_samples, ignore_index=True)\n",
        "    return pd.concat([df, df_augmented], ignore_index=True)\n",
        "\n",
        "# Secondary data augmentation\n",
        "df_secondary_augmented = augment_data(df_secondary, 2000)\n",
        "\n",
        "print(\"Secondary data size after augmentation:\", df_secondary_augmented.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhGaV8uaK6B3",
        "outputId": "5e815523-91e5-4642-f3fb-772a9fa874d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secondary data size after augmentation: (2006, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_secondary.to_csv('/content/drive/MyDrive/Research_project/secondary_traffic_data_augmented.csv', index=False)\n"
      ],
      "metadata": {
        "id": "uVcpGKoCLbOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns in merged dataset before drop:\")\n",
        "print(df_merged.columns)\n",
        "\n",
        "# Drop irrelevant columns carefully\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "existing_drop_cols = [c for c in drop_cols if c in df_merged.columns]\n",
        "print(\"Dropping columns:\", existing_drop_cols)\n",
        "df_merged = df_merged.drop(columns=existing_drop_cols)\n",
        "\n",
        "# Drop NaNs\n",
        "df_merged = df_merged.dropna()\n",
        "print(\"Shape after dropping NaNs:\", df_merged.shape)\n",
        "\n",
        "# Encode categorical columns\n",
        "for col in df_merged.select_dtypes(include=['object']).columns:\n",
        "    df_merged[col] = df_merged[col].astype('category').cat.codes\n",
        "\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "df_merged['binary_congestion'] = df_merged[target_col].apply(lambda x: 1 if x in [2, 3] else 0)\n",
        "\n",
        "# Prepare features and target carefully\n",
        "X = df_merged.drop(columns=[target_col, 'binary_congestion'], errors='ignore')\n",
        "y = df_merged['binary_congestion']\n",
        "\n",
        "print(\"Feature columns:\", X.columns)\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Length of y:\", len(y))\n",
        "\n",
        "# Check missing values\n",
        "print(\"Missing values in X:\", X.isnull().sum().sum())\n",
        "print(\"Missing values in y:\", y.isnull().sum())\n",
        "\n",
        "# Make sure X is not empty before split\n",
        "if X.shape[0] == 0 or X.shape[1] == 0:\n",
        "    print(\"Feature set is empty! Please check your data processing.\")\n",
        "else:\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63oaURKbLfPL",
        "outputId": "5c88f426-9592-40ec-815b-4671af403527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in merged dataset before drop:\n",
            "Index(['What is Your age Group', 'Gender',\n",
            "       'How often do you travel within Mumbai?',\n",
            "       'On average, how much time do you spend in traffic daily?',\n",
            "       'Which mode of transportation do you use most frequently?',\n",
            "       'How severe do you think traffic congestion is in Mumbai?',\n",
            "       'What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)',\n",
            "       'How does traffic congestion affect your daily life?',\n",
            "       'Are you aware that Artificial Intelligence can be used to predict traffic congestion?',\n",
            "       'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?',\n",
            "       'Which features would you like most in an AI-based traffic prediction app?',\n",
            "       'In your opinion, can AI help reduce traffic congestion in Mumbai?',\n",
            "       'pdf_file', 'accident_mentions', 'congestion_mentions',\n",
            "       'binary_congestion'],\n",
            "      dtype='object')\n",
            "Dropping columns: []\n",
            "Shape after dropping NaNs: (6, 16)\n",
            "Feature columns: Index(['What is Your age Group', 'Gender',\n",
            "       'How often do you travel within Mumbai?',\n",
            "       'On average, how much time do you spend in traffic daily?',\n",
            "       'Which mode of transportation do you use most frequently?',\n",
            "       'What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)',\n",
            "       'How does traffic congestion affect your daily life?',\n",
            "       'Are you aware that Artificial Intelligence can be used to predict traffic congestion?',\n",
            "       'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?',\n",
            "       'Which features would you like most in an AI-based traffic prediction app?',\n",
            "       'In your opinion, can AI help reduce traffic congestion in Mumbai?',\n",
            "       'pdf_file', 'accident_mentions', 'congestion_mentions'],\n",
            "      dtype='object')\n",
            "Shape of X: (6, 14)\n",
            "Length of y: 6\n",
            "Missing values in X: 0\n",
            "Missing values in y: 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before dropping NaNs:\")\n",
        "print(df_merged.info())\n",
        "\n",
        "# Missing values ko fill karo (example: zero se or forward fill)\n",
        "df_merged.fillna(method='ffill', inplace=True)\n",
        "df_merged.fillna(0, inplace=True)\n",
        "\n",
        "print(\"After filling NaNs:\")\n",
        "print(df_merged.info())\n",
        "\n",
        "# Fir encoding aur rest steps follow karo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjNOCY2vL7iz",
        "outputId": "61b2b610-05f6-4044-f6b7-bdc5ddb64a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before dropping NaNs:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 6 entries, 0 to 5\n",
            "Data columns (total 16 columns):\n",
            " #   Column                                                                                                        Non-Null Count  Dtype  \n",
            "---  ------                                                                                                        --------------  -----  \n",
            " 0   What is Your age Group                                                                                        6 non-null      int8   \n",
            " 1   Gender                                                                                                        6 non-null      int8   \n",
            " 2   How often do you travel within Mumbai?                                                                        6 non-null      int8   \n",
            " 3   On average, how much time do you spend in traffic daily?                                                      6 non-null      int8   \n",
            " 4   Which mode of transportation do you use most frequently?                                                      6 non-null      int8   \n",
            " 5   How severe do you think traffic congestion is in Mumbai?                                                      6 non-null      int8   \n",
            " 6   What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)                       6 non-null      int8   \n",
            " 7   How does traffic congestion affect your daily life?                                                           6 non-null      int8   \n",
            " 8   Are you aware that Artificial Intelligence can be used to predict traffic congestion?                         6 non-null      int8   \n",
            " 9   If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  6 non-null      int8   \n",
            " 10  Which features would you like most in an AI-based traffic prediction app?                                     6 non-null      int8   \n",
            " 11  In your opinion, can AI help reduce traffic congestion in Mumbai?                                             6 non-null      int8   \n",
            " 12  pdf_file                                                                                                      6 non-null      int8   \n",
            " 13  accident_mentions                                                                                             6 non-null      float64\n",
            " 14  congestion_mentions                                                                                           6 non-null      float64\n",
            " 15  binary_congestion                                                                                             6 non-null      int64  \n",
            "dtypes: float64(2), int64(1), int8(13)\n",
            "memory usage: 270.0 bytes\n",
            "None\n",
            "After filling NaNs:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 6 entries, 0 to 5\n",
            "Data columns (total 16 columns):\n",
            " #   Column                                                                                                        Non-Null Count  Dtype  \n",
            "---  ------                                                                                                        --------------  -----  \n",
            " 0   What is Your age Group                                                                                        6 non-null      int8   \n",
            " 1   Gender                                                                                                        6 non-null      int8   \n",
            " 2   How often do you travel within Mumbai?                                                                        6 non-null      int8   \n",
            " 3   On average, how much time do you spend in traffic daily?                                                      6 non-null      int8   \n",
            " 4   Which mode of transportation do you use most frequently?                                                      6 non-null      int8   \n",
            " 5   How severe do you think traffic congestion is in Mumbai?                                                      6 non-null      int8   \n",
            " 6   What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)                       6 non-null      int8   \n",
            " 7   How does traffic congestion affect your daily life?                                                           6 non-null      int8   \n",
            " 8   Are you aware that Artificial Intelligence can be used to predict traffic congestion?                         6 non-null      int8   \n",
            " 9   If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  6 non-null      int8   \n",
            " 10  Which features would you like most in an AI-based traffic prediction app?                                     6 non-null      int8   \n",
            " 11  In your opinion, can AI help reduce traffic congestion in Mumbai?                                             6 non-null      int8   \n",
            " 12  pdf_file                                                                                                      6 non-null      int8   \n",
            " 13  accident_mentions                                                                                             6 non-null      float64\n",
            " 14  congestion_mentions                                                                                           6 non-null      float64\n",
            " 15  binary_congestion                                                                                             6 non-null      int64  \n",
            "dtypes: float64(2), int64(1), int8(13)\n",
            "memory usage: 270.0 bytes\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-659082201.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_merged.fillna(method='ffill', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined = pd.concat([df_primary, df_secondary], ignore_index=True, sort=False)\n",
        "print(\"Combined dataset shape:\", df_combined.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJhoZvjoMHlw",
        "outputId": "63d78937-09a0-4318-e9ec-4a909ce6ddee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (63, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined = pd.concat([df_primary, df_secondary], ignore_index=True, sort=False)\n",
        "df_combined.to_csv('/content/drive/MyDrive/Research_project/combined_traffic_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "SZ3raY8AMZdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined = pd.concat([df_primary, df_secondary], ignore_index=True, sort=False)\n",
        "print(\"Combined before saving:\", df_combined.shape)\n",
        "df_combined.to_csv('/content/drive/MyDrive/Research_project/combined_traffic_data.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8LckdDqMn8b",
        "outputId": "768d3477-93cc-4c81-c38f-be2aad75def1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined before saving: (63, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Research_project/combined_traffic_data.csv')\n",
        "print(\"Loaded data shape:\", df.shape)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqEUKA-zMp9D",
        "outputId": "9340a5d7-db4f-4ff5-9b85-0f4c92d2f96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data shape: (63, 19)\n",
            "                 Timestamp                         Email               Name  \\\n",
            "0  2025-08-15 12:15:09.867    ashokkanojiya320@gmail.com    Ashok Kanojiya    \n",
            "1  2025-08-15 12:15:29.358      neetupandey582@gmail.com      Neetu pandey    \n",
            "2  2025-08-15 12:19:29.157       ankit233kumar@gmail.com       Ankit Kumar    \n",
            "3  2025-08-15 12:20:09.399     aditimahamulkar@gmail.com  Aditi Mahamulkar    \n",
            "4  2025-08-15 12:22:01.695  e1062240119@timscdrmumbai.in     Dhanush Dhotre   \n",
            "\n",
            "  What is Your age Group  Gender How often do you travel within Mumbai?  \\\n",
            "0            18–25 years    Male                                  Daily   \n",
            "1            18–25 years  Female                                  Daily   \n",
            "2            18–25 years    Male                       1–3 times a week   \n",
            "3            18–25 years  Female                                  Daily   \n",
            "4            18–25 years    Male                                  Daily   \n",
            "\n",
            "  On average, how much time do you spend in traffic daily?  \\\n",
            "0                                  Less than 30 mins         \n",
            "1                                  Less than 30 mins         \n",
            "2                                  Less than 30 mins         \n",
            "3                                  Less than 30 mins         \n",
            "4                                  Less than 30 mins         \n",
            "\n",
            "  Which mode of transportation do you use most frequently?  \\\n",
            "0                                              Metro         \n",
            "1                                        Local Train         \n",
            "2                                        Local Train         \n",
            "3                                        Local Train         \n",
            "4                         Private Vehicle (Car/Bike)         \n",
            "\n",
            "  How severe do you think traffic congestion is in Mumbai?  \\\n",
            "0                                           Moderate         \n",
            "1                                               High         \n",
            "2                                           Moderate         \n",
            "3                                               High         \n",
            "4                                               High         \n",
            "\n",
            "  What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)  \\\n",
            "0  Poor road infrastructure, Increasing number of...                                        \n",
            "1  Increasing number of private vehicles, Ineffic...                                        \n",
            "2  Increasing number of private vehicles, Road co...                                        \n",
            "3  Increasing number of private vehicles, Road co...                                        \n",
            "4  Poor road infrastructure, Increasing number of...                                        \n",
            "\n",
            "  How does traffic congestion affect your daily life?  \\\n",
            "0                    Missed appointments/work delays    \n",
            "1                             Stress and frustration    \n",
            "2                              No significant effect    \n",
            "3                            Higher fuel consumption    \n",
            "4                             Stress and frustration    \n",
            "\n",
            "  Are you aware that Artificial Intelligence can be used to predict traffic congestion?  \\\n",
            "0                                                Yes                                      \n",
            "1                                                Yes                                      \n",
            "2                                           Not Sure                                      \n",
            "3                                                Yes                                      \n",
            "4                                                 No                                      \n",
            "\n",
            "  If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  \\\n",
            "0                                             Likely                                                             \n",
            "1                                             Likely                                                             \n",
            "2                                        Very likely                                                             \n",
            "3                                             Likely                                                             \n",
            "4                                      Very unlikely                                                             \n",
            "\n",
            "  Which features would you like most in an AI-based traffic prediction app?  \\\n",
            "0  Real-time traffic updates, Alternative route s...                          \n",
            "1               Public transport timings integration                          \n",
            "2  Real-time traffic updates, Alternative route s...                          \n",
            "3                          Real-time traffic updates                          \n",
            "4                          Real-time traffic updates                          \n",
            "\n",
            "  In your opinion, can AI help reduce traffic congestion in Mumbai?  \\\n",
            "0                                Yes, to some extent                  \n",
            "1                                 Yes, significantly                  \n",
            "2                                           Not sure                  \n",
            "3                                 Yes, significantly                  \n",
            "4                     No, it won’t make a difference                  \n",
            "\n",
            "  What suggestions would you give to improve traffic congestion in Mumbai?  \\\n",
            "0  Promote more use of public transport like buse...                         \n",
            "1  \\nIncrease public transport frequency and prom...                         \n",
            "2  Underground roads , high frequency of buses an...                         \n",
            "3                                                NaN                         \n",
            "4  Use public vehicle as much as you can & road s...                         \n",
            "\n",
            "  pdf_file  accident_mentions  congestion_mentions  \n",
            "0      NaN                NaN                  NaN  \n",
            "1      NaN                NaN                  NaN  \n",
            "2      NaN                NaN                  NaN  \n",
            "3      NaN                NaN                  NaN  \n",
            "4      NaN                NaN                  NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Target column unique values:\", df['How severe do you think traffic congestion is in Mumbai?'].unique())\n",
        "print(\"Missing in target:\", df['How severe do you think traffic congestion is in Mumbai?'].isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXNW2N8AMteS",
        "outputId": "e98adee6-844d-4569-a0ea-134a5826987c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target column unique values: ['Moderate' 'High' 'Very High' 'Low' nan]\n",
            "Missing in target: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "\n",
        "target_mapping = {\n",
        "    'Low': 0,\n",
        "    'Moderate': 1,\n",
        "    'High': 2,\n",
        "    'Very High': 3\n",
        "}\n",
        "\n",
        "df[target_col] = df[target_col].map(target_mapping)\n",
        "df = df.dropna(subset=[target_col])\n",
        "\n",
        "df['binary_congestion'] = df[target_col].apply(lambda x: 1 if x >= 2 else 0)\n"
      ],
      "metadata": {
        "id": "9Tj4GkDlM7Ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Paths to your files\n",
        "primary_path = '/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "secondary_augmented_path = '/content/drive/MyDrive/Research_project/secondary_traffic_data_augmented.csv'\n",
        "\n",
        "# Load datasets\n",
        "df_primary = pd.read_excel(primary_path, sheet_name='Form Responses 1')\n",
        "df_secondary = pd.read_csv(secondary_augmented_path)\n",
        "\n",
        "# Strip column spaces\n",
        "df_primary.columns = df_primary.columns.str.strip()\n",
        "df_secondary.columns = df_secondary.columns.str.strip()\n",
        "\n",
        "# Combine data (concatenate rows)\n",
        "df_combined = pd.concat([df_primary, df_secondary], ignore_index=True, sort=False)\n",
        "\n",
        "print(\"Combined dataset shape:\", df_combined.shape)\n",
        "\n",
        "# Drop irrelevant cols\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "df_combined.drop(columns=[c for c in drop_cols if c in df_combined.columns], inplace=True, errors='ignore')\n",
        "\n",
        "# Handle missing values carefully: drop rows with missing target\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "df_combined = df_combined.dropna(subset=[target_col])\n",
        "\n",
        "# Map target to numeric values\n",
        "target_mapping = {\n",
        "    'Low': 0,\n",
        "    'Moderate': 1,\n",
        "    'High': 2,\n",
        "    'Very High': 3\n",
        "}\n",
        "df_combined[target_col] = df_combined[target_col].map(target_mapping)\n",
        "\n",
        "# Optionally create binary target\n",
        "df_combined['binary_congestion'] = df_combined[target_col].apply(lambda x: 1 if x >= 2 else 0)\n",
        "\n",
        "# Encode categorical features to numeric\n",
        "for col in df_combined.select_dtypes(include=['object']).columns:\n",
        "    df_combined[col] = df_combined[col].astype('category').cat.codes\n",
        "\n",
        "# Prepare features and label\n",
        "X = df_combined.drop(columns=[target_col, 'binary_congestion'], errors='ignore')\n",
        "y = df_combined['binary_congestion']\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest model\n",
        "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions & evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX0qdZUcNCuF",
        "outputId": "d1bcfd5a-646b-4795-d8b1-1d24ebcf042d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Combined dataset shape: (63, 19)\n",
            "Features shape: (57, 14)\n",
            "Target shape: (57,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       0.64      0.88      0.74         8\n",
            "\n",
            "    accuracy                           0.58        12\n",
            "   macro avg       0.32      0.44      0.37        12\n",
            "weighted avg       0.42      0.58      0.49        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Paths\n",
        "primary_path = '/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "secondary_path = '/content/drive/MyDrive/Research_project/secondary_traffic_data.csv'\n",
        "\n",
        "# Load data\n",
        "df_primary = pd.read_excel(primary_path, sheet_name='Form Responses 1')\n",
        "df_secondary = pd.read_csv(secondary_path)\n",
        "\n",
        "# Clean columns\n",
        "df_primary.columns = df_primary.columns.str.strip()\n",
        "df_secondary.columns = df_secondary.columns.str.strip()\n",
        "\n",
        "# Augmentation function\n",
        "def augment_data(df, n_samples):\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    synthetic_samples = []\n",
        "    for _ in range(n_samples):\n",
        "        sample = df.sample(1).copy()\n",
        "        for col in numeric_cols:\n",
        "            noise = np.random.normal(0, 0.1 * abs(sample[col].values[0]))\n",
        "            sample[col] += noise\n",
        "        synthetic_samples.append(sample)\n",
        "    df_augmented = pd.concat(synthetic_samples, ignore_index=True)\n",
        "    return pd.concat([df, df_augmented], ignore_index=True)\n",
        "\n",
        "# Augment secondary data to 2000+\n",
        "df_secondary_aug = augment_data(df_secondary, 2000)\n",
        "\n",
        "# Combine data (simple concat)\n",
        "df_combined = pd.concat([df_primary, df_secondary_aug], ignore_index=True, sort=False)\n",
        "\n",
        "# Drop irrelevant columns\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "df_combined.drop(columns=[c for c in drop_cols if c in df_combined.columns], inplace=True, errors='ignore')\n",
        "\n",
        "# Drop rows with missing target\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "df_combined = df_combined.dropna(subset=[target_col])\n",
        "\n",
        "# Map target to numeric\n",
        "target_mapping = {'Low': 0, 'Moderate': 1, 'High': 2, 'Very High': 3}\n",
        "df_combined[target_col] = df_combined[target_col].map(target_mapping)\n",
        "\n",
        "# Binary target: congestion yes/no\n",
        "df_combined['binary_congestion'] = df_combined[target_col].apply(lambda x: 1 if x >= 2 else 0)\n",
        "\n",
        "# Encode categorical features\n",
        "for col in df_combined.select_dtypes(include=['object']).columns:\n",
        "    df_combined[col] = df_combined[col].astype('category').cat.codes\n",
        "\n",
        "# Prepare features & target\n",
        "X = df_combined.drop(columns=[target_col, 'binary_congestion'], errors='ignore')\n",
        "y = df_combined['binary_congestion']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Final dataset shape:\", df_combined.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xogv86ctOEKq",
        "outputId": "e45d9851-bab3-4723-c04f-74959a26c82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         4\n",
            "           1       0.64      0.88      0.74         8\n",
            "\n",
            "    accuracy                           0.58        12\n",
            "   macro avg       0.32      0.44      0.37        12\n",
            "weighted avg       0.42      0.58      0.49        12\n",
            "\n",
            "Final dataset shape: (57, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies (run once)\n",
        "# !pip install imblearn xgboost --quiet\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# File paths\n",
        "primary_path = '/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "secondary_path = '/content/drive/MyDrive/Research_project/secondary_traffic_data.csv'\n",
        "\n",
        "# Load data\n",
        "df_primary = pd.read_excel(primary_path, sheet_name='Form Responses 1')\n",
        "df_secondary = pd.read_csv(secondary_path)\n",
        "\n",
        "df_primary.columns = df_primary.columns.str.strip()\n",
        "df_secondary.columns = df_secondary.columns.str.strip()\n",
        "\n",
        "# Combine data\n",
        "df_combined = pd.concat([df_primary, df_secondary], ignore_index=True, sort=False)\n",
        "\n",
        "# Drop irrelevant columns\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "df_combined.drop(columns=[c for c in drop_cols if c in df_combined.columns], inplace=True, errors='ignore')\n",
        "\n",
        "# Drop rows with missing target\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "df_combined = df_combined.dropna(subset=[target_col])\n",
        "\n",
        "# Map target labels\n",
        "target_mapping = {'Low': 0, 'Moderate': 1, 'High': 2, 'Very High': 3}\n",
        "df_combined[target_col] = df_combined[target_col].map(target_mapping)\n",
        "\n",
        "# Create binary target\n",
        "df_combined['binary_congestion'] = df_combined[target_col].apply(lambda x: 1 if x >= 2 else 0)\n",
        "\n",
        "# Encode categorical columns\n",
        "for col in df_combined.select_dtypes(include=['object']).columns:\n",
        "    df_combined[col] = df_combined[col].astype('category').cat.codes\n",
        "\n",
        "# Features and target\n",
        "X = df_combined.drop(columns=[target_col, 'binary_congestion'], errors='ignore')\n",
        "y = df_combined['binary_congestion']\n",
        "\n",
        "# Drop columns with 100% missing (NaN)\n",
        "X = X.loc[:, X.isnull().mean() < 1]\n",
        "\n",
        "# Impute missing values\n",
        "imp = SimpleImputer(strategy='most_frequent')\n",
        "X_imputed = pd.DataFrame(imp.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Balance classes with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X_imputed, y)\n",
        "\n",
        "print(\"Class distribution after SMOTE:\")\n",
        "print(pd.Series(y_res).value_counts())\n",
        "\n",
        "# XGBoost model + hyperparameter tuning\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_res, y_res)\n",
        "\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Best model training and evaluation\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_res)\n",
        "\n",
        "print(\"Classification report on balanced dataset:\")\n",
        "print(classification_report(y_res, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_res, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_F46jm2Q0Vx",
        "outputId": "0706b5ce-60f4-4cfa-9ca6-dcf6d5990a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Class distribution after SMOTE:\n",
            "binary_congestion\n",
            "0    44\n",
            "1    44\n",
            "Name: count, dtype: int64\n",
            "Best hyperparameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100}\n",
            "Classification report on balanced dataset:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        44\n",
            "           1       1.00      1.00      1.00        44\n",
            "\n",
            "    accuracy                           1.00        88\n",
            "   macro avg       1.00      1.00      1.00        88\n",
            "weighted avg       1.00      1.00      1.00        88\n",
            "\n",
            "Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:50:33] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split (before SMOTE)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_imputed, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# SMOTE only on training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Training class distribution after SMOTE:\")\n",
        "print(pd.Series(y_train_res).value_counts())\n",
        "\n",
        "# Train XGBoost on resampled training data\n",
        "best_params = grid_search.best_params_ if 'grid_search' in globals() else {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1}\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, **best_params)\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Predict on test data\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Classification report on test data:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PajVnT5VRlTR",
        "outputId": "ef828642-2409-4e47-f778-e3680ef966bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training class distribution after SMOTE:\n",
            "binary_congestion\n",
            "1    35\n",
            "0    35\n",
            "Name: count, dtype: int64\n",
            "Classification report on test data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.33      0.33         3\n",
            "           1       0.78      0.78      0.78         9\n",
            "\n",
            "    accuracy                           0.67        12\n",
            "   macro avg       0.56      0.56      0.56        12\n",
            "weighted avg       0.67      0.67      0.67        12\n",
            "\n",
            "Test Accuracy: 0.6666666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:50:33] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "# !pip install lightgbm imblearn --quiet\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import re\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# File paths\n",
        "primary_path = '/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "secondary_path = '/content/drive/MyDrive/Research_project/secondary_traffic_data.csv'\n",
        "\n",
        "# Load data\n",
        "df_primary = pd.read_excel(primary_path, sheet_name='Form Responses 1')\n",
        "df_secondary = pd.read_csv(secondary_path)\n",
        "\n",
        "df_primary.columns = df_primary.columns.str.strip()\n",
        "df_secondary.columns = df_secondary.columns.str.strip()\n",
        "\n",
        "df_combined = pd.concat([df_primary, df_secondary], ignore_index=True, sort=False)\n",
        "\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "df_combined.drop(columns=[c for c in drop_cols if c in df_combined.columns], inplace=True, errors='ignore')\n",
        "\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "df_combined = df_combined.dropna(subset=[target_col])\n",
        "\n",
        "target_mapping = {'Low': 0, 'Moderate': 1, 'High': 2, 'Very High': 3}\n",
        "df_combined[target_col] = df_combined[target_col].map(target_mapping)\n",
        "df_combined['binary_congestion'] = df_combined[target_col].apply(lambda x: 1 if x >= 2 else 0)\n",
        "\n",
        "for col in df_combined.select_dtypes(include=['object']).columns:\n",
        "    df_combined[col] = df_combined[col].astype('category').cat.codes\n",
        "\n",
        "X = df_combined.drop(columns=[target_col, 'binary_congestion'], errors='ignore')\n",
        "y = df_combined['binary_congestion']\n",
        "\n",
        "# Clean feature names - replace special chars with underscore\n",
        "def clean_col_name(name):\n",
        "    return re.sub(r'\\W+', '_', name)\n",
        "X.columns = [clean_col_name(col) for col in X.columns]\n",
        "\n",
        "# Drop columns with all NaNs (if any)\n",
        "X = X.loc[:, X.isnull().mean() < 1]\n",
        "\n",
        "imp = SimpleImputer(strategy='most_frequent')\n",
        "X_imputed = pd.DataFrame(imp.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_imputed, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# SMOTE on train data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Train class distribution after SMOTE:\")\n",
        "print(pd.Series(y_train_res).value_counts())\n",
        "\n",
        "model = lgb.LGBMClassifier(random_state=42)\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 50],\n",
        "    'max_depth': [-1, 5, 10],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [50, 100, 150]\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"Best LightGBM params:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "print(\"Classification report on test set:\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiUih-hnR2eR",
        "outputId": "8577a565-297a-426a-8bd1-c40bd5faecc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train class distribution after SMOTE:\n",
            "binary_congestion\n",
            "1    35\n",
            "0    35\n",
            "Name: count, dtype: int64\n",
            "[LightGBM] [Info] Number of positive: 35, number of negative: 35\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 59\n",
            "[LightGBM] [Info] Number of data points in the train set: 70, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Best LightGBM params: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 31}\n",
            "Classification report on test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.33      0.33         3\n",
            "           1       0.78      0.78      0.78         9\n",
            "\n",
            "    accuracy                           0.67        12\n",
            "   macro avg       0.56      0.56      0.56        12\n",
            "weighted avg       0.67      0.67      0.67        12\n",
            "\n",
            "Test Accuracy: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost --quiet\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load and preprocess data (aapka pehle wala data preparation code yahan rahega)\n",
        "\n",
        "# Impute missing values\n",
        "imp = SimpleImputer(strategy='most_frequent')\n",
        "X_imputed = pd.DataFrame(imp.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_imputed, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# SMOTE on train data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Ensemble of CatBoost and RandomForest\n",
        "cat_model = CatBoostClassifier(random_seed=42, verbose=0)\n",
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[('cat', cat_model), ('rf', rf_model)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "ensemble_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "y_pred = ensemble_model.predict(X_test)\n",
        "\n",
        "print(\"Ensemble classification report on test data:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mxyfy6fSo49",
        "outputId": "87d4943a-ec6e-466a-a43a-f516066dea79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hEnsemble classification report on test data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.33      0.33         3\n",
            "           1       0.78      0.78      0.78         9\n",
            "\n",
            "    accuracy                           0.67        12\n",
            "   macro avg       0.56      0.56      0.56        12\n",
            "weighted avg       0.67      0.67      0.67        12\n",
            "\n",
            "Test Accuracy: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages if not installed\n",
        "# !pip install catboost imblearn --quiet\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import re\n",
        "\n",
        "# Mount drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load and prepare data as before\n",
        "primary_path = '/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "secondary_path = '/content/drive/MyDrive/Research_project/secondary_traffic_data.csv'\n",
        "df_primary = pd.read_excel(primary_path, sheet_name='Form Responses 1')\n",
        "df_secondary = pd.read_csv(secondary_path)\n",
        "df_primary.columns = df_primary.columns.str.strip()\n",
        "df_secondary.columns = df_secondary.columns.str.strip()\n",
        "df_combined = pd.concat([df_primary, df_secondary], ignore_index=True, sort=False)\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "df_combined.drop(columns=[c for c in drop_cols if c in df_combined.columns], inplace=True, errors='ignore')\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "df_combined = df_combined.dropna(subset=[target_col])\n",
        "target_mapping = {'Low': 0, 'Moderate': 1, 'High': 2, 'Very High': 3}\n",
        "df_combined[target_col] = df_combined[target_col].map(target_mapping)\n",
        "df_combined['binary_congestion'] = df_combined[target_col].apply(lambda x: 1 if x >= 2 else 0)\n",
        "for col in df_combined.select_dtypes(include=['object']).columns:\n",
        "    df_combined[col] = df_combined[col].astype('category').cat.codes\n",
        "X = df_combined.drop(columns=[target_col, 'binary_congestion'], errors='ignore')\n",
        "y = df_combined['binary_congestion']\n",
        "def clean_col_name(name):\n",
        "    return re.sub(r'\\W+', '_', name)\n",
        "X.columns = [clean_col_name(col) for col in X.columns]\n",
        "X = X.loc[:, X.isnull().mean() < 1]\n",
        "\n",
        "# Imputation\n",
        "imp = SimpleImputer(strategy='most_frequent')\n",
        "X_imputed = pd.DataFrame(imp.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_imputed, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# SMOTE on train set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Train class distribution after SMOTE:\", pd.Series(y_train_res).value_counts())\n",
        "\n",
        "# Define base learners\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('cat', CatBoostClassifier(random_seed=42, verbose=0))\n",
        "]\n",
        "\n",
        "# Meta learner\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# Create stacking classifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_learner,\n",
        "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
        "    n_jobs=-1,\n",
        "    passthrough=True\n",
        ")\n",
        "\n",
        "# Hyperparameter tuning parameters\n",
        "param_grid = {\n",
        "    'final_estimator__C': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(stacking_clf, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"Best meta-learner C parameter:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict and evaluate on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Stacking ensemble classification report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbc5E-L6T21z",
        "outputId": "87ad0d1c-29eb-4c40-ac0f-3488feb678b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train class distribution after SMOTE: binary_congestion\n",
            "1    35\n",
            "0    35\n",
            "Name: count, dtype: int64\n",
            "Best meta-learner C parameter: {'final_estimator__C': 1}\n",
            "Stacking ensemble classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.33      0.33         3\n",
            "           1       0.78      0.78      0.78         9\n",
            "\n",
            "    accuracy                           0.67        12\n",
            "   macro avg       0.56      0.56      0.56        12\n",
            "weighted avg       0.67      0.67      0.67        12\n",
            "\n",
            "Test accuracy: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive mount karen (agar pehle mount nahi kiya hai)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "\n",
        "# Step 1: Data load karen - file path apne Drive ke hisaab se adjust karen\n",
        "file_path = r'/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "df = pd.read_excel(file_path, sheet_name='Form Responses 1')\n",
        "\n",
        "# Step 2: Columns check karen\n",
        "print(\"Columns in dataset:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Step 3: Unwanted columns hataen (agar exist karte hain)\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "actual_drop_cols = [c for c in drop_cols if c in df.columns]\n",
        "df_clean = df.drop(columns=actual_drop_cols).dropna()\n",
        "\n",
        "# Step 4: Categorical columns ko numeric banayen\n",
        "for col in df_clean.select_dtypes(include='object').columns:\n",
        "    df_clean[col] = df_clean[col].astype('category').cat.codes\n",
        "\n",
        "# Step 5: Target column name check karen aur list print karen\n",
        "print(\"Columns after cleaning:\")\n",
        "print(df_clean.columns.tolist())\n",
        "\n",
        "# Step 6: Target column ka exact name identify karen\n",
        "# Example ke liye niche ek generic target column use kiya hai, agar column name alag ho toh yeh replace karen:\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "if target_col not in df_clean.columns:\n",
        "    print(f\"Error: Target column '{target_col}' not found. Please check column names printed above and update target_col variable accordingly.\")\n",
        "else:\n",
        "    # Step 7: Binary target banayen (adjust logic agar needed ho)\n",
        "    df_clean['binary_congestion'] = df_clean[target_col].apply(lambda x: 1 if x in [2,3] else 0)\n",
        "\n",
        "    # Step 8: Features aur target define karen\n",
        "    X = df_clean.drop(columns=[target_col, 'binary_congestion'])\n",
        "    y = df_clean['binary_congestion']\n",
        "\n",
        "    # Step 9: Train-test split karen\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Step 10: Imbalanced dataset ke liye SMOTE apply karen (optional)\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Step 11: Model train karen\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(X_train_res, y_train_res)\n",
        "\n",
        "    # Step 12: Model evaluation\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "    # Step 13: Model save karen\n",
        "    save_path = '/content/drive/MyDrive/Research_project/trained_traffic_model.pkl'\n",
        "    joblib.dump(model, save_path)\n",
        "    print(f\"Model saved at {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szR-HVgMWBjy",
        "outputId": "94cb0c57-5f86-4aee-b395-8f4c555e5ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Columns in dataset:\n",
            "['Timestamp', 'Email', 'Name ', 'What is Your age Group', 'Gender', 'How often do you travel within Mumbai?  ', 'On average, how much time do you spend in traffic daily? ', 'Which mode of transportation do you use most frequently? ', 'How severe do you think traffic congestion is in Mumbai?  ', 'What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)', 'How does traffic congestion affect your daily life?  ', 'Are you aware that Artificial Intelligence can be used to predict traffic congestion?  ', 'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  ', 'Which features would you like most in an AI-based traffic prediction app?  ', 'In your opinion, can AI help reduce traffic congestion in Mumbai?  ', 'What suggestions would you give to improve traffic congestion in Mumbai?  ']\n",
            "Columns after cleaning:\n",
            "['Name ', 'What is Your age Group', 'Gender', 'How often do you travel within Mumbai?  ', 'On average, how much time do you spend in traffic daily? ', 'Which mode of transportation do you use most frequently? ', 'How severe do you think traffic congestion is in Mumbai?  ', 'What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)', 'How does traffic congestion affect your daily life?  ', 'Are you aware that Artificial Intelligence can be used to predict traffic congestion?  ', 'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  ', 'Which features would you like most in an AI-based traffic prediction app?  ', 'In your opinion, can AI help reduce traffic congestion in Mumbai?  ', 'What suggestions would you give to improve traffic congestion in Mumbai?  ']\n",
            "Error: Target column 'How severe do you think traffic congestion is in Mumbai?' not found. Please check column names printed above and update target_col variable accordingly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Columns check karen aur trailing spaces remove karen\n",
        "print(\"Columns in dataset before strip:\")\n",
        "print(df.columns.tolist())\n",
        "df.columns = df.columns.str.strip()\n",
        "print(\"Columns in dataset after strip:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Step 3: Unwanted columns hataen\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "actual_drop_cols = [c for c in drop_cols if c in df.columns]\n",
        "df_clean = df.drop(columns=actual_drop_cols).dropna()\n",
        "\n",
        "# Step 4: Columns strip karen df_clean me bhi\n",
        "df_clean.columns = df_clean.columns.str.strip()\n",
        "\n",
        "# Step 5: Categorical columns ko numeric banayen\n",
        "for col in df_clean.select_dtypes(include='object').columns:\n",
        "    df_clean[col] = df_clean[col].astype('category').cat.codes\n",
        "\n",
        "# Step 6: Target column set karen without trailing spaces\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "\n",
        "# Baaki steps same rahenge\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_gobWCEX2_s",
        "outputId": "4b8ba2c7-faf8-402d-99ec-16a8d0f86655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in dataset before strip:\n",
            "['Timestamp', 'Email', 'Name ', 'What is Your age Group', 'Gender', 'How often do you travel within Mumbai?  ', 'On average, how much time do you spend in traffic daily? ', 'Which mode of transportation do you use most frequently? ', 'How severe do you think traffic congestion is in Mumbai?  ', 'What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)', 'How does traffic congestion affect your daily life?  ', 'Are you aware that Artificial Intelligence can be used to predict traffic congestion?  ', 'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?  ', 'Which features would you like most in an AI-based traffic prediction app?  ', 'In your opinion, can AI help reduce traffic congestion in Mumbai?  ', 'What suggestions would you give to improve traffic congestion in Mumbai?  ']\n",
            "Columns in dataset after strip:\n",
            "['Timestamp', 'Email', 'Name', 'What is Your age Group', 'Gender', 'How often do you travel within Mumbai?', 'On average, how much time do you spend in traffic daily?', 'Which mode of transportation do you use most frequently?', 'How severe do you think traffic congestion is in Mumbai?', 'What do you think are the main causes of traffic congestion in Mumbai? (choose up to 3)', 'How does traffic congestion affect your daily life?', 'Are you aware that Artificial Intelligence can be used to predict traffic congestion?', 'If an AI app could predict traffic and suggest the fastest route in real-time, how likely are you to use it?', 'Which features would you like most in an AI-based traffic prediction app?', 'In your opinion, can AI help reduce traffic congestion in Mumbai?', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "\n",
        "# Drive mount agar pehle se mounted nahi hai toh\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Data load karen (path ko apne laut Drive location se adjust karein)\n",
        "file_path = r'/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "df = pd.read_excel(file_path, sheet_name='Form Responses 1')\n",
        "\n",
        "# Columns ka trimming (trailing spaces remove) karen\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Kuch unwanted columns drop karen, jo current data me exist karte hain\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "actual_drop_cols = [c for c in drop_cols if c in df.columns]\n",
        "df_clean = df.drop(columns=actual_drop_cols).dropna()\n",
        "\n",
        "# Categorical features ko numeric me convert karen\n",
        "for col in df_clean.select_dtypes(include='object').columns:\n",
        "    df_clean[col] = df_clean[col].astype('category').cat.codes\n",
        "\n",
        "# Target column specify karen\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "\n",
        "# Binary target banayen (traffic severe ya nahi)\n",
        "df_clean['binary_congestion'] = df_clean[target_col].apply(lambda x: 1 if x in [2,3] else 0)\n",
        "\n",
        "# Features aur target banayen\n",
        "X = df_clean.drop(columns=[target_col, 'binary_congestion'])\n",
        "y = df_clean['binary_congestion']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# SMOTE apply karke imbalance handle karen\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Random Forest model train karen\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Test data pe predict karen aur evaluate karen\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# Model save karen Drive me\n",
        "save_path = r'/content/drive/MyDrive/Research_project/trained_traffic_model.pkl'\n",
        "joblib.dump(model, save_path)\n",
        "print(f\"Model saved at {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzsM8_zJX_xD",
        "outputId": "91fc5493-1b1a-45ee-822a-f7aa60a8c861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.57      0.57         7\n",
            "           1       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.50        12\n",
            "   macro avg       0.49      0.49      0.49        12\n",
            "weighted avg       0.50      0.50      0.50        12\n",
            "\n",
            "Model saved at /content/drive/MyDrive/Research_project/trained_traffic_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# 1. Drive mount karen\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 2. Data load karen\n",
        "file_path = r'/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "df = pd.read_excel(file_path, sheet_name='Form Responses 1')\n",
        "\n",
        "# 3. Column names strip karen\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# 4. Unwanted columns drop karen\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "actual_drop_cols = [c for c in drop_cols if c in df.columns]\n",
        "df_clean = df.drop(columns=actual_drop_cols).dropna()\n",
        "\n",
        "# 5. Categorical columns ko numeric banayen\n",
        "for col in df_clean.select_dtypes(include='object').columns:\n",
        "    df_clean[col] = df_clean[col].astype('category').cat.codes\n",
        "\n",
        "# 6. Target column set karen or binary target banayen\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "df_clean['binary_congestion'] = df_clean[target_col].apply(lambda x: 1 if x in [2,3] else 0)\n",
        "\n",
        "# 7. Features aur target set karen\n",
        "X = df_clean.drop(columns=[target_col, 'binary_congestion'])\n",
        "y = df_clean['binary_congestion']\n",
        "\n",
        "# 8. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 9. SMOTE se imbalance handle karen\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# 10. Model train karen\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# 11. Model evaluate karen\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# 12. Features list save karen\n",
        "features = X.columns.tolist()\n",
        "joblib.dump(features, '/content/drive/MyDrive/Research_project/features_list.pkl')\n",
        "\n",
        "# 13. Model save karen\n",
        "joblib.dump(model, '/content/drive/MyDrive/Research_project/trained_traffic_model.pkl')\n",
        "print(\"Model and features saved successfully.\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Prediction step code (alag se run karen jab prediction karna ho)\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "# Model aur features load karen\n",
        "model = joblib.load('/content/drive/MyDrive/Research_project/trained_traffic_model.pkl')\n",
        "features = joblib.load('/content/drive/MyDrive/Research_project/features_list.pkl')\n",
        "\n",
        "# New data load karen\n",
        "new_data = pd.read_csv('/content/drive/MyDrive/Research_project/secondary_traffic_data.csv')\n",
        "\n",
        "# Columns strip karen\n",
        "new_data.columns = new_data.columns.str.strip()\n",
        "\n",
        "# Categorical columns encode karen\n",
        "for col in new_data.select_dtypes(include='object').columns:\n",
        "    new_data[col] = new_data[col].astype('category').cat.codes\n",
        "\n",
        "# Missing features add karen with zeros\n",
        "for feat in features:\n",
        "    if feat not in new_data.columns:\n",
        "        new_data[feat] = 0\n",
        "\n",
        "# Extra columns drop karen\n",
        "new_data = new_data[features]\n",
        "\n",
        "# Prediction karen\n",
        "predictions = model.predict(new_data)\n",
        "\n",
        "# Predictions add karen dataframe me\n",
        "new_data['predicted_congestion'] = predictions\n",
        "\n",
        "# Result print karen\n",
        "print(new_data[['predicted_congestion']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSamvvdPYQ_f",
        "outputId": "4665886c-f533-450b-d7cd-5348a1512e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.57      0.57         7\n",
            "           1       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.50        12\n",
            "   macro avg       0.49      0.49      0.49        12\n",
            "weighted avg       0.50      0.50      0.50        12\n",
            "\n",
            "Model and features saved successfully.\n",
            "   predicted_congestion\n",
            "0                     1\n",
            "1                     1\n",
            "2                     1\n",
            "3                     1\n",
            "4                     1\n",
            "5                     1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Data load & preprocessing same rakhna as before\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pipeline with SMOTE and XGBoost\n",
        "pipeline = Pipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter grid search\n",
        "param_grid = {\n",
        "    'xgb__n_estimators': [50, 100, 200],\n",
        "    'xgb__max_depth': [3, 5, 7],\n",
        "    'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
        "    'xgb__subsample': [0.7, 1.0]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
        "\n",
        "# Train\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid.best_estimator_\n",
        "print(f\"Best params: {grid.best_params_}\")\n",
        "\n",
        "# Evaluate\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save model\n",
        "import joblib\n",
        "joblib.dump(best_model, '/content/drive/MyDrive/Research_project/final_xgb_model.pkl')\n",
        "print(\"Final tuned model saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b_LvetRZFL7",
        "outputId": "03d32b1a-e713-465d-fae1-0bddd8a7bed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:25] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:25] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:25] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:26] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:26] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:26] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:26] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:27] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:27] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:28] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:28] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:29] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:29] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:30] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:30] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:32] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:32] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:33] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:34] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:34] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:34] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:35] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:35] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:36] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:36] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:36] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:36] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:36] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:36] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:36] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:37] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:37] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:37] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:37] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:38] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:38] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:39] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:39] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:40] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:41] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:42] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:42] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:44] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:45] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:45] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:46] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:47] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:47] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:47] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:48] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:48] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:48] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:49] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:49] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:50] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:50] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:50] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:50] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:51] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:51] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:51] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:51] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:52] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:53] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:53] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:54] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:54] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:55] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:58] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:58] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:58] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:52:59] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:00] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:00] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:00] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:00] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:00] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:01] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:01] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:02] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:02] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:02] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:03] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:03] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:03] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:04] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:05] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:05] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:06] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:09] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:09] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:10] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:10] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:10] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:11] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:11] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:11] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:12] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:12] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:12] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:12] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:12] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:53:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'xgb__learning_rate': 0.2, 'xgb__max_depth': 3, 'xgb__n_estimators': 200, 'xgb__subsample': 1.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.57      0.57         7\n",
            "           1       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.50        12\n",
            "   macro avg       0.49      0.49      0.49        12\n",
            "weighted avg       0.50      0.50      0.50        12\n",
            "\n",
            "Final tuned model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "\n",
        "# Drive mount karen\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Data load karen\n",
        "primary_path = r'/content/drive/MyDrive/Research_project/Predicting Traffic Congestion in Mumbai Using AI (Responses).xlsx'\n",
        "secondary_path = r'/content/drive/MyDrive/Research_project/secondary_traffic_data_augmented.csv'\n",
        "\n",
        "primary_df = pd.read_excel(primary_path, sheet_name='Form Responses 1')\n",
        "secondary_df = pd.read_csv(secondary_path)\n",
        "\n",
        "primary_df.columns = primary_df.columns.str.strip()\n",
        "secondary_df.columns = secondary_df.columns.str.strip()\n",
        "\n",
        "# Drop unwanted columns\n",
        "drop_cols = ['Timestamp', 'Email', 'Name', 'What suggestions would you give to improve traffic congestion in Mumbai?']\n",
        "actual_drop_cols = [c for c in drop_cols if c in primary_df.columns]\n",
        "primary_df_clean = primary_df.drop(columns=actual_drop_cols)\n",
        "\n",
        "# Encode categorical features\n",
        "for col in primary_df_clean.select_dtypes(include='object').columns:\n",
        "    primary_df_clean[col] = primary_df_clean[col].astype('category').cat.codes\n",
        "\n",
        "for col in secondary_df.select_dtypes(include='object').columns:\n",
        "    secondary_df[col] = secondary_df[col].astype('category').cat.codes\n",
        "\n",
        "# Merge or concatenate datasets\n",
        "try:\n",
        "    merged_df = pd.merge(primary_df_clean, secondary_df, on='common_key')  # Update 'common_key' if exists\n",
        "except:\n",
        "    merged_df = pd.concat([primary_df_clean, secondary_df], ignore_index=True)\n",
        "\n",
        "# Handle missing values by filling with mean/mode\n",
        "merged_df = merged_df.fillna(merged_df.mean())\n",
        "\n",
        "# If categorical columns exist after filling\n",
        "for col in merged_df.select_dtypes(include='category').columns:\n",
        "    merged_df[col] = merged_df[col].fillna(merged_df[col].mode()[0])\n",
        "\n",
        "# Create binary target\n",
        "target_col = 'How severe do you think traffic congestion is in Mumbai?'\n",
        "merged_df['binary_congestion'] = merged_df[target_col].apply(lambda x: 1 if x in [2,3] else 0)\n",
        "\n",
        "# Define features and target\n",
        "X = merged_df.drop(columns=[target_col, 'binary_congestion'])\n",
        "y = merged_df['binary_congestion']\n",
        "\n",
        "# Fill NaNs in features if any left\n",
        "X = X.fillna(X.mean())\n",
        "for col in X.select_dtypes(include='category').columns:\n",
        "    X[col] = X[col].fillna(X[col].mode()[0])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# SMOTE oversampling on training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Train RandomForest model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# Save model and feature list\n",
        "joblib.dump(model, '/content/drive/MyDrive/Research_project/augmented_trained_model.pkl')\n",
        "joblib.dump(X.columns.tolist(), '/content/drive/MyDrive/Research_project/features_list.pkl')\n",
        "print(\"Augmented model and features saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VOj7TixZ4Bu",
        "outputId": "dc4a0191-ee7b-45ba-d75b-2998bb890176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       0.83      0.83      0.83         6\n",
            "\n",
            "    accuracy                           0.85        13\n",
            "   macro avg       0.85      0.85      0.85        13\n",
            "weighted avg       0.85      0.85      0.85        13\n",
            "\n",
            "Augmented model and features saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# 1. Model aur features load karo\n",
        "model = joblib.load('/content/drive/MyDrive/Research_project/augmented_trained_model.pkl')\n",
        "features = joblib.load('/content/drive/MyDrive/Research_project/features_list.pkl')\n",
        "\n",
        "# 2. Naya unseen data load karo\n",
        "new_data_path = '/content/drive/MyDrive/Research_project/secondary_traffic_data.csv'  # Ya jo bhi naya data file ho\n",
        "new_data = pd.read_csv(new_data_path)\n",
        "\n",
        "# 3. Columns trim karo aur categorical columns ko encode karo\n",
        "new_data.columns = new_data.columns.str.strip()\n",
        "\n",
        "for col in new_data.select_dtypes(include='object').columns:\n",
        "    new_data[col] = new_data[col].astype('category').cat.codes\n",
        "\n",
        "# 4. Missing feature columns ko zero se fill karo\n",
        "for feat in features:\n",
        "    if feat not in new_data.columns:\n",
        "        new_data[feat] = 0\n",
        "\n",
        "# 5. Extra columns drop karo\n",
        "new_data = new_data[features]\n",
        "\n",
        "# 6. Model se prediction lo\n",
        "predictions = model.predict(new_data)\n",
        "\n",
        "# 7. Prediction results ko data me add karo\n",
        "new_data['predicted_congestion'] = predictions\n",
        "\n",
        "# 8. Result print karo\n",
        "print(new_data[['predicted_congestion']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOr6HoVIg1xA",
        "outputId": "cac485bd-8d06-4037-bf55-4935f0184f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   predicted_congestion\n",
            "0                     1\n",
            "1                     1\n",
            "2                     1\n",
            "3                     1\n",
            "4                     1\n",
            "5                     1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Model aur features load karo\n",
        "model = joblib.load('/content/drive/MyDrive/Research_project/augmented_trained_model.pkl')\n",
        "features = joblib.load('/content/drive/MyDrive/Research_project/features_list.pkl')\n",
        "\n",
        "# Naya unseen data load karo\n",
        "new_data_path = '/content/drive/MyDrive/Research_project/secondary_traffic_data.csv'\n",
        "new_data = pd.read_csv(new_data_path)\n",
        "\n",
        "# Columns trim karo\n",
        "new_data.columns = new_data.columns.str.strip()\n",
        "\n",
        "# Categorical encoding same tarike se karo\n",
        "for col in new_data.select_dtypes(include='object').columns:\n",
        "    new_data[col] = new_data[col].astype('category').cat.codes\n",
        "\n",
        "# Missing features add karo with zeros\n",
        "for feat in features:\n",
        "    if feat not in new_data.columns:\n",
        "        new_data[feat] = 0\n",
        "\n",
        "# Extra columns drop karo\n",
        "new_data = new_data[features]\n",
        "\n",
        "# Probability predict karo\n",
        "probs = model.predict_proba(new_data)[:,1]  # Class 1 ka probability\n",
        "\n",
        "# Threshold define karo for classification\n",
        "threshold = 0.5  # Aap ise adjust kar sakte hain\n",
        "\n",
        "# Prediction based on threshold\n",
        "preds = (probs >= threshold).astype(int)\n",
        "\n",
        "# Dataframe me add karo\n",
        "new_data['predicted_probability'] = probs\n",
        "new_data['predicted_congestion'] = preds\n",
        "\n",
        "# Results dikhao\n",
        "print(new_data[['predicted_probability', 'predicted_congestion']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnO5v0ichKfT",
        "outputId": "ff7f3920-c7fa-4991-fd6e-0e2fc212a33b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   predicted_probability  predicted_congestion\n",
            "0                   0.60                     1\n",
            "1                   0.57                     1\n",
            "2                   0.60                     1\n",
            "3                   0.58                     1\n",
            "4                   0.60                     1\n",
            "5                   0.57                     1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.7\n",
        "preds = (probs >= threshold).astype(int)\n",
        "new_data['predicted_congestion'] = preds\n",
        "print(new_data[['predicted_probability', 'predicted_congestion']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEcuzPbPhZZW",
        "outputId": "f9c8d50a-16f0-43f1-d2cf-6831c7d68ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   predicted_probability  predicted_congestion\n",
            "0                   0.60                     0\n",
            "1                   0.57                     0\n",
            "2                   0.60                     0\n",
            "3                   0.58                     0\n",
            "4                   0.60                     0\n",
            "5                   0.57                     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# y_test is actual labels for test data (train-test split me defined tha)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
        "\n",
        "plt.plot(thresholds, tpr, label='True Positive Rate')\n",
        "plt.plot(thresholds, fpr, label='False Positive Rate')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Rate')\n",
        "plt.title('ROC curve vs Threshold')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "s_CCCM_7hjgB",
        "outputId": "2eb47e9e-26c6-4659-cf1a-cb2ab3a750b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Apna trained model wahan load karo jahan saved ho\n",
        "model = joblib.load('/content/drive/MyDrive/Research_project/augmented_trained_model.pkl')  # apne model path ke hisab se update karo\n",
        "\n",
        "# Agar aapke model me feature_names_in_ attribute hai tab use karo, varna manually feature names define karo\n",
        "if hasattr(model, 'feature_names_in_'):\n",
        "    features = model.feature_names_in_.tolist()\n",
        "else:\n",
        "    # Agar aapke paas training data ka feature list already hai toh use load karke\n",
        "    # yahan manually list bhi de sakte hain jaise:\n",
        "    # features = ['feature1', 'feature2', 'feature3']\n",
        "    print(\"Model me feature names nahi hain. Feature list manually dena hoga.\")\n",
        "    features = []\n",
        "\n",
        "# Feature list ko file me save karo\n",
        "joblib.dump(features, '/content/drive/MyDrive/Research_project/features_list.pkl')\n",
        "print(\"Features list saved successfully.\")\n"
      ],
      "metadata": {
        "id": "O3L2F413lJRu",
        "outputId": "18d3abc3-dc69-4fbe-fa13-5456b1462fb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features list saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "areas = [\n",
        "    \"Churchgate\", \"Marine Lines\", \"Charni Road\", \"Grant Road\", \"Mumbai Central\", \"Mahalaxmi\",\n",
        "    \"Lower Parel\", \"Prabhadevi\", \"Dadar\", \"Matunga Road\", \"Mahim\", \"Bandra\", \"Khar Road\",\n",
        "    \"Santacruz\", \"Vile Parle\", \"Andheri\", \"Goregaon\", \"Malad\", \"Kandivali\", \"Borivali\",\n",
        "    \"Dahisar\", \"Mira Road\", \"Bhayandar\", \"Vasai Road\", \"CSMT\", \"Masjid\", \"Sandhurst Road\",\n",
        "    \"Byculla\", \"Chinchpokli\", \"Parel\", \"Currey Road\", \"Matunga\",\n",
        "    \"Sion\", \"Kurla\", \"Vidyavihar\", \"Ghatkopar\", \"Vikhroli\", \"Kanjur Marg\",\n",
        "    \"Bhandup\", \"Mulund\", \"Thane\"\n",
        "]\n",
        "\n",
        "n_samples = 2000\n",
        "np.random.seed(42)\n",
        "\n",
        "data = {\n",
        "    \"Area\": np.random.choice(areas, n_samples),\n",
        "    \"Day\": np.random.choice([\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"], n_samples),\n",
        "    \"Hour\": np.random.randint(0, 24, n_samples),\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "def congestion_label(row):\n",
        "    score = 0\n",
        "    # Approximate peak hour logic\n",
        "    if 7 <= row[\"Hour\"] <= 11 or 17 <= row[\"Hour\"] <= 21:\n",
        "        score += 1\n",
        "    # Example: congested areas have more weight\n",
        "    if row[\"Area\"] in [\"Kandivali\", \"Andheri\", \"Borivali\", \"Dadar\", \"CSMT\", \"Thane\"]:\n",
        "        score += 1\n",
        "    return 1 if score >= 2 else 0\n",
        "\n",
        "df[\"Congestion\"] = df.apply(congestion_label, axis=1)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAUa93jACAGM",
        "outputId": "466cb71f-5945-492c-c2e1-d4722a5babc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Area      Day  Hour  Congestion\n",
            "0      Bhandup  Tuesday     4           0\n",
            "1  Chinchpokli   Monday     5           0\n",
            "2   Vile Parle   Sunday     6           0\n",
            "3   Prabhadevi  Tuesday    20           0\n",
            "4      Dahisar   Friday     0           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le_area = LabelEncoder()\n",
        "df[\"Area_enc\"] = le_area.fit_transform(df[\"Area\"])\n",
        "\n",
        "le_day = LabelEncoder()\n",
        "df[\"Day_enc\"] = le_day.fit_transform(df[\"Day\"])\n",
        "\n",
        "features = [\"Area_enc\", \"Day_enc\", \"Hour\"]\n",
        "X = df[features]\n",
        "y = df[\"Congestion\"]\n"
      ],
      "metadata": {
        "id": "g-0nxPH1FyEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxsPd9I5F3ZB",
        "outputId": "a5b0e85b-d00c-4654-b94a-5f567956a6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9675\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       380\n",
            "           1       1.00      0.35      0.52        20\n",
            "\n",
            "    accuracy                           0.97       400\n",
            "   macro avg       0.98      0.68      0.75       400\n",
            "weighted avg       0.97      0.97      0.96       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_area = input(\"Enter area (e.g., Kandivali): \")\n",
        "input_day = input(\"Enter day (e.g., Monday): \")\n",
        "input_hour_str = input(\"Enter current hour (0-23 or HH:MM): \")\n",
        "\n",
        "try:\n",
        "    input_hour = int(input_hour_str.split(\":\")[0])\n",
        "except:\n",
        "    print(\"Invalid hour format. Please enter hour as 0-23 or HH:MM.\")\n",
        "    raise\n",
        "\n",
        "try:\n",
        "    area_val = le_area.transform([input_area])[0]\n",
        "    day_val = le_day.transform([input_day.capitalize()])[0]\n",
        "except ValueError:\n",
        "    print(\"Input error: Area or Day not recognized. Check spelling and capitalization.\")\n",
        "else:\n",
        "    input_features = [[area_val, day_val, input_hour]]\n",
        "    prediction = model.predict(input_features)[0]\n",
        "    if prediction == 1:\n",
        "        print(f\"Traffic congestion likely in {input_area} now.\")\n",
        "    else:\n",
        "        print(f\"Traffic likely smooth in {input_area} now.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMPwWJyqF7Iz",
        "outputId": "1685b993-dfe3-4b31-f48f-7cfb74e50a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter area (e.g., Kandivali): Kandivali\n",
            "Enter day (e.g., Monday): Monday\n",
            "Enter current hour (0-23 or HH:MM): 12:30\n",
            "Traffic likely smooth in Kandivali now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Yeh Colab ya Flask me ek script ke roop me chalega)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Areas list (Mumbai stations)\n",
        "areas = [\n",
        "    \"Churchgate\", \"Marine Lines\", \"Charni Road\", \"Grant Road\", \"Mumbai Central\", \"Mahalaxmi\",\n",
        "    \"Lower Parel\", \"Prabhadevi\", \"Dadar\", \"Matunga Road\", \"Mahim\", \"Bandra\", \"Khar Road\",\n",
        "    \"Santacruz\", \"Vile Parle\", \"Andheri\", \"Goregaon\", \"Malad\", \"Kandivali\", \"Borivali\",\n",
        "    \"Dahisar\", \"Mira Road\", \"Bhayandar\", \"Vasai Road\", \"CSMT\", \"Masjid\", \"Sandhurst Road\",\n",
        "    \"Byculla\", \"Chinchpokli\", \"Parel\", \"Currey Road\", \"Matunga\",\n",
        "    \"Sion\", \"Kurla\", \"Vidyavihar\", \"Ghatkopar\", \"Vikhroli\", \"Kanjur Marg\",\n",
        "    \"Bhandup\", \"Mulund\", \"Thane\"\n",
        "]\n",
        "\n",
        "n_samples = 5000\n",
        "np.random.seed(42)\n",
        "\n",
        "data = {\n",
        "    \"Area\": np.random.choice(areas, n_samples),\n",
        "    \"Day\": np.random.choice([\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"], n_samples),\n",
        "    \"Hour\": np.random.randint(0, 24, n_samples),\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "def congestion_label(row):\n",
        "    score = 0\n",
        "    if 7 <= row[\"Hour\"] <= 11 or 17 <= row[\"Hour\"] <= 21:\n",
        "        score += 1\n",
        "    if row[\"Area\"] in [\"Kandivali\", \"Andheri\", \"Borivali\", \"Dadar\", \"CSMT\", \"Thane\"]:\n",
        "        score += 1\n",
        "    return 1 if score >= 2 else 0\n",
        "\n",
        "df[\"Congestion\"] = df.apply(congestion_label, axis=1)\n",
        "\n",
        "# Label encode\n",
        "le_area = LabelEncoder()\n",
        "le_day = LabelEncoder()\n",
        "df[\"Area_enc\"] = le_area.fit_transform(df[\"Area\"])\n",
        "df[\"Day_enc\"] = le_day.fit_transform(df[\"Day\"])\n",
        "\n",
        "X = df[[\"Area_enc\", \"Day_enc\", \"Hour\"]]\n",
        "y = df[\"Congestion\"]\n",
        "\n",
        "# Train RandomForest\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "irAOdj8EHmod",
        "outputId": "b06613bf-fe30-4854-fb79-f1c1dda3b4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'model.pkl')\n",
        "joblib.dump(le_area, 'labelencoder_area.pkl')\n",
        "joblib.dump(le_day, 'labelencoder_day.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jco7VTd2J9oM",
        "outputId": "a217811b-1af4-4909-ec96-d65727ed9833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['labelencoder_day.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_X = [[le_area.transform(['Dadar'])[0], le_day.transform(['Monday'])[0], 9],   # Peak hour\n",
        "          [le_area.transform(['Kandivali'])[0], le_day.transform(['Friday'])[0], 18]]  # Peak hour\n",
        "\n",
        "model.predict(test_X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBhDvRx0Nxpf",
        "outputId": "495081d2-2122-4902-db2c-dd1a7a0f1c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def congestion_label(row):\n",
        "    score = 0\n",
        "    if 7 <= row[\"Hour\"] <= 11 or 17 <= row[\"Hour\"] <= 21:\n",
        "        score += 2  # Peak hours weight badhaya\n",
        "    if row[\"Area\"] in [\"Kandivali\", \"Andheri\", \"Borivali\", \"Dadar\", \"CSMT\", \"Thane\"]:\n",
        "        score += 1\n",
        "    return 1 if score >= 2 else 0\n"
      ],
      "metadata": {
        "id": "tCkIIcrWUpy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n"
      ],
      "metadata": {
        "id": "cuBHppV4UtE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'model.pkl')\n",
        "joblib.dump(le_area, 'labelencoder_area.pkl')\n",
        "joblib.dump(le_day, 'labelencoder_day.pkl')\n"
      ],
      "metadata": {
        "id": "v9aAF1rUUxoc",
        "outputId": "69df6356-d547-4451-dd2f-59b3c02dd657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['labelencoder_day.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "6-xxbvd_d-qZ",
        "outputId": "57787490-1651-4625-a264-a11e063e0d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'model.pkl')\n",
        "joblib.dump(le_area, 'labelencoder_area.pkl')\n",
        "joblib.dump(le_day, 'labelencoder_day.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp00QLdHeAef",
        "outputId": "2a399c24-7f71-4fca-dae2-cc9aff5e5c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['labelencoder_day.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Step 1: Naye aur purane stations ki list bana lo\n",
        "stations = [\n",
        "    \"Churchgate\", \"Marine Lines\", \"Charni Road\", \"Grant Road\", \"Mumbai Central\", \"Mahalaxmi\", \"Lower Parel\",\n",
        "    \"Elphinstone Road\", \"Dadar\", \"Malad\", \"Andheri\", \"Kandivali\", \"Mira Road\", \"Vasai\", \"Virar\",\n",
        "    \"CSMT\", \"Masjid\", \"Sandhurst Road\", \"Byculla\", \"Dadar Central\", \"Kurla\", \"Vidyavihar\",\n",
        "    \"Ghatkopar\", \"Vikhroli\", \"Kanjurmarg\", \"Bhandup\", \"Mulund\", \"Thane\", \"Diva\", \"Kalyan\"\n",
        "]\n",
        "\n",
        "days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "hours = list(range(24))\n",
        "\n",
        "# Step 2: Synthetic data generation (example, aap realistic data ke liye customize kar sakte hain)\n",
        "data = []\n",
        "for station in stations:\n",
        "    for day in days:\n",
        "        for hour in hours:\n",
        "            congestion = 0\n",
        "            # Example congestion condition\n",
        "            if station in [\"Dadar\", \"Andheri\", \"Borivali\", \"CSMT\", \"Thane\"] and (7 <= hour <= 11 or 17 <= hour <= 21):\n",
        "                congestion = 1\n",
        "            data.append([station, day, hour, congestion])\n",
        "\n",
        "df = pd.DataFrame(data, columns=[\"Area\", \"Day\", \"Hour\", \"Congestion\"])\n",
        "\n",
        "# Step 3: Encode categorical variables\n",
        "le_area = LabelEncoder()\n",
        "le_day = LabelEncoder()\n",
        "df[\"Area_enc\"] = le_area.fit_transform(df[\"Area\"])\n",
        "df[\"Day_enc\"] = le_day.fit_transform(df[\"Day\"])\n",
        "\n",
        "# Step 4: Prepare train data\n",
        "X = df[[\"Area_enc\", \"Day_enc\", \"Hour\"]]\n",
        "y = df[\"Congestion\"]\n",
        "\n",
        "# Step 5: Train model\n",
        "model = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Step 6: Save model and encoders\n",
        "joblib.dump(model, 'model.pkl')\n",
        "joblib.dump(le_area, 'labelencoder_area.pkl')\n",
        "joblib.dump(le_day, 'labelencoder_day.pkl')\n",
        "\n",
        "print(\"Model and encoders saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn4kPw-tjk91",
        "outputId": "f7d8b204-f7f7-4bc4-9cb0-1e87b5d46e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and encoders saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Y4LiDgZxkbHQ",
        "outputId": "11f382e7-b3b1-4e3c-8cd8-59407f0bd746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'model.pkl')\n",
        "joblib.dump(le_area, 'labelencoder_area.pkl')\n",
        "joblib.dump(le_day, 'labelencoder_day.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0KJjr39kc8-",
        "outputId": "fdfd72fe-0f8e-4bd8-a7dd-32768e308c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['labelencoder_day.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "stations = [\n",
        "    \"Churchgate\", \"Marine Lines\", \"Charni Road\", \"Grant Road\", \"Mumbai Central\", \"Mahalaxmi\",\n",
        "    \"Lower Parel\", \"Elphinstone Road\", \"Dadar\", \"Malad\", \"Andheri\", \"Kandivali\", \"Mira Road\",\n",
        "    \"Vasai\", \"Virar\", \"CSMT\", \"Masjid\", \"Sandhurst Road\", \"Byculla\", \"Dadar Central\", \"Kurla\",\n",
        "    \"Vidyavihar\", \"Ghatkopar\", \"Vikhroli\", \"Kanjurmarg\", \"Bhandup\", \"Mulund\", \"Thane\", \"Diva\",\n",
        "    \"Kalyan\", \"WEH Bandra\", \"WEH Kandivali\", \"WEH Borivali\", \"WEH Dahisar\", \"WEH Vasai\",\n",
        "    \"EEH Ghatkopar\", \"EEH Mulund\", \"EEH Thane\", \"EEH Bhiwandi\"\n",
        "]\n",
        "\n",
        "days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "hours = list(range(24))\n",
        "\n",
        "# Synthetic data generate karo\n",
        "data = []\n",
        "for station in stations:\n",
        "    for day in days:\n",
        "        for hour in hours:\n",
        "            congestion = 1 if station in [\"Dadar\", \"Andheri\", \"CSMT\", \"Thane\", \"WEH Bandra\", \"EEH Thane\"] and (7 <= hour <= 11 or 17 <= hour <= 21) else 0\n",
        "            data.append([station, day, hour, congestion])\n",
        "\n",
        "df = pd.DataFrame(data, columns=[\"Area\", \"Day\", \"Hour\", \"Congestion\"])\n",
        "\n",
        "# Label encoding\n",
        "le_area = LabelEncoder()\n",
        "le_area.fit(stations)  # Yahan important hai - pure stations yahan fit karna\n",
        "le_day = LabelEncoder()\n",
        "le_day.fit(days)\n",
        "\n",
        "df[\"Area_enc\"] = le_area.transform(df[\"Area\"])\n",
        "df[\"Day_enc\"] = le_day.transform(df[\"Day\"])\n",
        "\n",
        "X = df[[\"Area_enc\", \"Day_enc\", \"Hour\"]]\n",
        "y = df[\"Congestion\"]\n",
        "\n",
        "# Model train\n",
        "model = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Files save karo\n",
        "joblib.dump(model, \"model.pkl\")\n",
        "joblib.dump(le_area, \"labelencoder_area.pkl\")\n",
        "joblib.dump(le_day, \"labelencoder_day.pkl\")\n",
        "\n",
        "print(\"Nayi model files ban gayi hain, Flask folder me replace kar do.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d10J3uustAJ1",
        "outputId": "abd1bdae-2782-4e0d-f80d-4c94ea30f77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nayi model files ban gayi hain, Flask folder me replace kar do.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stations)\n",
        "print(le_area.classes_)\n"
      ],
      "metadata": {
        "id": "uWtHhWnStnYy",
        "outputId": "5814c40c-5f06-4865-e486-2ec540b96f77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Churchgate', 'Marine Lines', 'Charni Road', 'Grant Road', 'Mumbai Central', 'Mahalaxmi', 'Lower Parel', 'Elphinstone Road', 'Dadar', 'Malad', 'Andheri', 'Kandivali', 'Mira Road', 'Vasai', 'Virar', 'CSMT', 'Masjid', 'Sandhurst Road', 'Byculla', 'Dadar Central', 'Kurla', 'Vidyavihar', 'Ghatkopar', 'Vikhroli', 'Kanjurmarg', 'Bhandup', 'Mulund', 'Thane', 'Diva', 'Kalyan', 'WEH Bandra', 'WEH Kandivali', 'WEH Borivali', 'WEH Dahisar', 'WEH Vasai', 'EEH Ghatkopar', 'EEH Mulund', 'EEH Thane', 'EEH Bhiwandi']\n",
            "['Andheri' 'Bhandup' 'Byculla' 'CSMT' 'Charni Road' 'Churchgate' 'Dadar'\n",
            " 'Dadar Central' 'Diva' 'EEH Bhiwandi' 'EEH Ghatkopar' 'EEH Mulund'\n",
            " 'EEH Thane' 'Elphinstone Road' 'Ghatkopar' 'Grant Road' 'Kalyan'\n",
            " 'Kandivali' 'Kanjurmarg' 'Kurla' 'Lower Parel' 'Mahalaxmi' 'Malad'\n",
            " 'Marine Lines' 'Masjid' 'Mira Road' 'Mulund' 'Mumbai Central'\n",
            " 'Sandhurst Road' 'Thane' 'Vasai' 'Vidyavihar' 'Vikhroli' 'Virar'\n",
            " 'WEH Bandra' 'WEH Borivali' 'WEH Dahisar' 'WEH Kandivali' 'WEH Vasai']\n"
          ]
        }
      ]
    }
  ]
}